Index,ReviewVenue,PublicationVenue,ConferenceTrack,Title,Authors,AuthorPDF,Abstract,ExplanationPage,Preregistered,DataCollectionMaterials,Data,ComputationalMatrials,Video,Talk,DOI,PublicationYear,ConferenceYear,ConferenceRoom,ConferenceDay,ConferenceSession,date,ConferenceTimeStart,ConferenceTimeEnd
1,VAST,TVCG,Other,FlowSense: A Natural Language Interface for Visual Data Exploration within a Dataflow System,"Bowen Yu, Claudio T. Silva",https://arxiv.org/pdf/1908.00681.pdf,"Dataflow visualization systems enable flexible visual data exploration by allowing the user to construct a dataflow diagram that composes query and visualization modules to specify system functionality. However learning dataflow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataflow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataflow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataflow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataflow context awareness. With FlowSense the user can expand and adjust dataflow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-flow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study.",,,,,https://github.com/yubowenok/flowsense,vimeo 360154533,vimeo 368702648,10.1109/TVCG.2019.2934668,2019,2019,Ballroom ABC,Tuesday,VIS Best Paper Awards,22-Oct,10:00 AM,10:15 AM
2,InfoVis,TVCG,Other,Data Changes Everything: Challenges and Opportunities in Data Visualization Design Handoff,"Jagoda Walny, Christian Frisson, Mieka West, Doris Kosminsky, Søren Knudsen, Sheelagh Carpendale, Wesley Willett",https://arxiv.org/pdf/1908.00192.pdf,"Complex data visualization design projects often entail collaboration between people with different visualization-related skills. For example, many teams include both designers who create new visualization designs and developers who implement the resulting visualization software. We identify gaps between data characterization tools, visualization design tools, and development platforms that pose challenges for designer-developer teams working to create new data visualizations. While it is common for commercial interaction design tools to support collaboration between designers and developers, creating data visualizations poses several unique challenges that are not supported by current tools. In particular, visualization designers must characterize and build an understanding of the underlying data, then specify layouts, data encodings, and other data-driven parameters that will be robust across many different data values. In larger teams, designers must also clearly communicate these mappings and their dependencies to developers, clients, and other collaborators. We report observations and reflections from five large multidisciplinary visualization design projects and highlight six data-specific visualization challenges for design specification and handoff. These challenges include adapting to changing data, anticipating edge cases in data, understanding technical challenges, articulating data-dependent interactions, communicating data mappings, and preserving the integrity of data mappings across iterations. Based on these observations, we identify opportunities for future tools for prototyping, testing, and communicating data-driven designs, which might contribute to more successful and collaborative data visualization design.",,,,,,vimeo 360483702,vimeo 368703151,10.1109/TVCG.2019.2934538,2019,2019,Ballroom ABC,Tuesday,VIS Best Paper Awards,22-Oct,10:15 AM,10:30 AM
3,SciVis,TVCG,Other,InSituNet: Deep Image Synthesis for Parameter Space Exploration of Ensemble Simulations,"Wenbin He, Junpeng Wang, Hanqi Guo, Ko-Chih Wang, Han-Wei Shen, Mukund Raj, Youssef S. G. Nashed, Tom Peterka",https://arxiv.org/pdf/1908.00407.pdf,"We propose InSituNet, a deep learning based surrogate model to support parameter space exploration for ensemble simulations that are visualized in situ. In situ visualization, generating visualizations at simulation time, is becoming prevalent in handling large-scale simulations because of the I/O and storage constraints. However, in situ visualization approaches limit the flexibility of post-hoc exploration because the raw simulation data are no longer available. Although multiple image-based approaches have been proposed to mitigate this limitation, those approaches lack the ability to explore the simulation parameters. Our approach allows flexible exploration of parameter space for large-scale ensemble simulations by taking advantage of the recent advances in deep learning. Specifically, we design InSituNet as a convolutional regression model to learn the mapping from the simulation and visualization parameters to the visualization results. With the trained model, users can generate new images for different simulation parameters under various visualization settings, which enables in-depth analysis of the underlying ensemble simulations. We demonstrate the effectiveness of InSituNet in combustion, cosmology, and ocean simulations through quantitative and qualitative evaluations.",,,,,,vimeo 359998980,vimeo 368709571,10.1109/TVCG.2019.2934312,2019,2019,Ballroom ABC,Tuesday,VIS Best Paper Awards,22-Oct,10:30 AM,10:45 AM
4,Short,Short,Other,Periphery Plots for Contextualizing Heterogeneous Time-Based Charts,"Bryce Morrow, Trevor Manz, Arlene E. Chung, Nils Gehlenborg, David Gotz",https://arxiv.org/pdf/1906.07637.pdf,"Patterns in temporal data can often be found across different scales, such as days, weeks, and months, making effective visualization of time-based data challenging. Here we propose a new approach for providing focus and context in time-based charts to enable interpretation of patterns across time scales. Our approach employs a focus zone with a time and a second axis, that can either represent quantities or categories, as well as a set of adjacent periphery plots that can aggregate data along the time, value, or both dimensions. We present a framework for periphery plots and describe two use cases that demonstrate the utility of our approach.",,,,,,vimeo 363453522,vimeo 368703866,,?,2019,Ballroom ABC,Tuesday,VIS Best Paper Awards,22-Oct,10:45 AM,11:00 AM
5,VAST,TVCG,VAST,NNVA: Neural Network Assisted Visual Analysis of Yeast Cell Polarization Simulation,"Subhashis Hazarika, Haoyu Li, Ko-Chih Wang, Han-Wei Shen, Ching-Shan Chou",https://arxiv.org/pdf/1904.09044.pdf,"Complex computational models are often designed to simulate real-world physical phenomena in many scientific disciplines. However, these simulation models tend to be computationally very expensive and involve a large number of simulation input parameters, which need to be analyzed and properly calibrated before the models can be applied for real scientific studies. We propose a visual analysis system to facilitate interactive exploratory analysis of high-dimensional input parameter space for a complex yeast cell polarization simulation. The proposed system can assist the computational biologists, who designed the simulation model, to visually calibrate the input parameters by modifying the parameter values and immediately visualizing the predicted simulation outcome without having the need to run the original expensive simulation for every instance. Our proposed visual analysis system is driven by a trained neural network-based surrogate model as the backend analysis framework. In this work, we demonstrate the advantage of using neural networks as surrogate models for visual analysis by incorporating some of the recent advances in the field of uncertainty quantification, interpretability and explainability of neural network-based models. We utilize the trained network to perform interactive parameter sensitivity analysis of the original simulation as well as recommend optimal parameter configurations using the activation maximization framework of neural networks. We also facilitate detail analysis of the trained network to extract useful insights about the simulation model, learned by the network, during the training process. We performed two case studies, and discovered multiple new parameter configurations, which can trigger high cell polarization results in the original simulation model. We evaluated our results by comparing with the original simulation model outcomes as well as the findings from previous parameter analysis performed by our experts.",,,,,,vimeo 360155766,vimeo 368441728,10.1109/TVCG.2019.2934591,2019,2019,Ballroom A,Tuesday,A Tour of VAST,22-Oct,2:35 PM,2:50 PM
6,VAST,TVCG,VAST,Supporting Analysis of Dimensionality Reduction Results with Contrastive Learning,"Takanori Fujiwara, Oh-Hyun Kwon, Kwan-Liu Ma",https://arxiv.org/pdf/1905.03911.pdf,"Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good first glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster’s characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature’s relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters’ feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.",,,,,,vimeo 360484919,vimeo 368441312,10.1109/TVCG.2019.2934251,2019,2019,Ballroom A,Tuesday,A Tour of VAST,22-Oct,2:50 PM,3:05 PM
7,VAST,TVCG,VAST,The What-If Tool: Interactive Probing of Machine Learning Models,"James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda Viegas, Jimbo Wilson",https://arxiv.org/pdf/1907.04135.pdf,"A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.",,,,,https://pair-code.github.io/what-if-tool/,vimeo 360154686,vimeo 368443363,10.1109/TVCG.2019.2934619,2019,2019,Ballroom A,Tuesday,A Tour of VAST,22-Oct,3:05 PM,3:20 PM
8,VAST,TVCG,VAST,Understanding the Role of Alternatives in Data Analysis Practices,"Jiali Liu, Nadia Boukhelifa, James Eagan",https://hal.telecom-paristech.fr/hal-02182349/document,"Data workers are people who perform data analysis activities as a part of their daily work but do not formally identify as data scientists. They come from various domains and often need to explore diverse sets of hypotheses and theories, a variety of data sources, algorithms, methods, tools, and visual designs. Taken together, we call these alternatives. To better understand and characterize the role of alternatives in their analyses, we conducted semi-structured interviews with 12 data workers with different types of expertise. We conducted four types of analyses to understand 1) why data workers explore alternatives; 2) the different notions of alternatives and how they fit into the sensemaking process; 3) the high-level processes around alternatives; and 4) their strategies to generate, explore, and manage those alternatives. We find that participants’ diverse levels of domain and computational expertise, experience with different tools, and collaboration within their broader context play an important role in how they explore these alternatives. These findings call out the need for more attention towards a deeper understanding of alternatives and the need for better tools to facilitate the exploration, interpretation, and management of alternatives. Drawing upon these analyses and findings, we present a framework based on participants’ 1) degree of attention, 2) abstraction level, and 3) analytic processes. We show how this framework can help understand how data workers consider such alternatives in their analyses and how tool designers might create tools to better support them.",,,,,,vimeo 360155794,vimeo 368440457,10.1109/TVCG.2019.2934593,2019,2019,Ballroom A,Tuesday,A Tour of VAST,22-Oct,3:20 PM,3:35 PM
9,VAST,TVCG,VAST,VASABI: Doing User Behaviour Analytics through Interactive Visual Hierarchical User Profiles,"Phong H. Nguyen, Rafael Henkin, Siming Chen, Natalia Andrienko, Gennady Andrienko, Olivier Thonnard, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/22591/1/vasabi___VAST_2019.pdf,"User behaviour analytics (UBA) systems offer sophisticated models that capture users’ behaviour over time with an aim to identify fraudulent activities that do not match their profiles. Making decisions based on such systems; however, requires an in-depth understanding of user behaviour both at an individual and at a group level where a group can consist of users with similar roles. We present a visual analytics approach to help analysts gain a comprehensive, multifaceted understanding of user behaviour at multiple levels. We take a user-centred approach to design a visual analytics framework supporting the analysis of collections of users and the numerous sessions of activities they conduct within digital applications. The framework is centred around the concept of hierarchical user profiles, where the profiles are built based on features derived from sessions they perform and visualised with task-informed designs to facilitate interactive exploration and investigation. We also present techniques to extract user tasks that summarise the behaviour and to cluster users according to these tasks to construct hierarchical user profiles. We externalise a series of analysis goals and tasks, and evaluate our methods through use cases conducted with experts. We observe that with the aid of interactive visual hierarchical user profiles, analysts were able to conduct exploratory and investigative analysis effectively, and able to understand the characteristics of user behaviour to make informed decisions whilst evaluating suspicious users and activities.",,,,,,vimeo 360156177,vimeo 368440126,,2019,2019,Ballroom A,Tuesday,A Tour of VAST,22-Oct,3:35 PM,3:50 PM
10,InfoVis,TVCG,InfoVis,Criteria for Rigor in Visualization Design Study,"Miriah Meyer, Jason Dykes",https://arxiv.org/pdf/1907.08495.pdf,"We develop a new perspective on research conducted through visualization design study that emphasizes design as a method of inquiry and the broad range of knowledge-contributions achieved through it as multiple, subjective, and socially constructed. From this interpretivist position we explore the nature of visualization design study and develop six criteria for rigor. We propose that rigor is established and judged according to the extent to which visualization design study research and its reporting are INFORMED , REFLEXIVE , ABUNDANT , PLAUSIBLE , RESONANT, and TRANSPARENT. This perspective and the criteria were constructed through a four-year engagement with the discourse around rigor and the nature of knowledge in social science, information systems, and design. We suggest methods from cognate disciplines that can support visualization researchers in meeting these criteria during the planning, execution, and reporting of design study. Through a series of deliberately provocative questions, we explore implications of this new perspective for design study research in visualization, concluding that as a discipline, visualization is not yet well positioned to embrace, nurture, and fully benefit from a rigorous, interpretivist approach to design study. The perspective and criteria we present are intended to stimulate dialogue and debate around the nature of visualization design study and the broader underpinnings of the discipline.",,,,,,vimeo 361976920,,,2019,2019,Ballroom B,Tuesday,Provocations,22-Oct,2:35 PM,2:50 PM
11,InfoVis,TVCG,InfoVis,Data by proxy – material traces as autographic visualizations,Dietmar Offenhuber,https://arxiv.org/pdf/1907.05454.pdf,"Information visualization limits itself, per definition, to the domain of symbolic information. This paper discusses arguments why the field should also consider forms of data that are not symbolically encoded, including physical traces and material indicators. Continuing a provocation presented by Pat Hanrahan in his 2004 IEEE Vis capstone address, this paper compares physical traces to visualizations and describes the techniques and visual practices for producing, revealing, and interpreting them. By contrasting information visualization with a speculative counter model of autographic visualization, this paper examines the design principles for material data. Autographic visualization addresses limitations of information visualization, such as the inability to directly reflect the material circumstances of data generation. The comparison between the two models allows probing the epistemic assumptions behind information visualization and uncovers linkages with the rich history of scientific visualization and trace reading. The paper begins by discussing the gap between data visualizations and their corresponding phenomena and proceeds by investigating how material visualizations can bridge this gap. It contextualizes autographic visualization with paradigms such as data physicalization and indexical visualization and grounds it in the broader theoretical literature of semiotics, science and technology studies (STS), and the history of scientific representation. The main section of the paper proposes a foundational design vocabulary for autographic visualization and offers examples of how citizen scientists already use autographic principles in their displays, which seem to violate the canonical principles of information visualization but succeed at fulfilling other rhetorical purposes in evidence construction. The paper concludes with a discussion of the limitations of autographic visualization, a roadmap for the empirical investigation of trace perception, and thoughts about how information visualization and autographic visualization techniques can contribute to each other",,,,,,vimeo 360050094,,,2019,2019,Ballroom B,Tuesday,Provocations,22-Oct,2:50 PM,3:05 PM
12,InfoVis,TVCG,InfoVis,Design by Immersion: A Transdisciplinary Approach to Problem-Driven Visualizations,"Kyle Wm Hall, Adam James Bradley, Uta Hinrichs, Samuel Huron, Jo Wood, Christopher Collins, Sheelagh Carpendale",https://arxiv.org/pdf/1908.00559.pdf,"While previous work exists on how to conduct and disseminate insights from problem-driven visualization projects and design studies, the literature does not address how to accomplish these goals in transdisciplinary teams in ways that advance all disciplines involved. In this paper we introduce and define a new methodological paradigm we call design by immersion, which provides an alternative perspective on problem-driven visualization work. Design by immersion embeds transdisciplinary experiences at the center of the visualization process by having visualization researchers participate in the work of the target domain (or domain experts participate in visualization research). Based on our own combined experiences of working on cross-disciplinary, problemdriven visualization projects, we present six case studies that expose the opportunities that design by immersion enables, including (1) exploring new domain-inspired visualization design spaces, (2) enriching domain understanding through personal experiences, and (3) building strong transdisciplinary relationships. Furthermore, we illustrate how the process of design by immersion opens up a diverse set of design activities that can be combined in different ways depending on the type of collaboration, project, and goals. Finally, we discuss the challenges and potential pitfalls of design by immersion.",,,,,,vimeo 360483922,,,2019,2019,Ballroom B,Tuesday,Provocations,22-Oct,3:05 PM,3:20 PM
13,InfoVis,TVCG,InfoVis,What is Interaction for Data Visualization?,"Evanthia Dimara, Charles Perin",https://hal.archives-ouvertes.fr/hal-02197062/document,"Interaction is fundamental to data visualization, but what “interaction” means in the context of visualization is ambiguous and confusing. We argue that this confusion is due to a lack of consensual definition. To tackle this problem, we start by synthesizing an inclusive view of interaction in the visualization community – including insights from information visualization, visual analytics and scientific visualization, as well as the input of both senior and junior visualization researchers. Once this view takes shape, we look at how interaction is defined in the field of human-computer interaction (HCI). By extracting commonalities and differences between the views of interaction in visualization and in HCI, we synthesize a definition of interaction for visualization. Our definition is meant to be a thinking tool and inspire novel and bolder interaction design practices. We hope that by better understanding what interaction in visualization is and what it can be, we will enrich the quality of interaction in visualization systems and empower those who use them.",,,,https://osf.io/ej7xg,,vimeo 360445743,,10.1109/TVCG.2019.2934283,2019,2019,Ballroom B,Tuesday,Provocations,22-Oct,3:20 PM,3:35 PM
14,InfoVis,TVCG,InfoVis,Why Authors Don't Visualize Uncertainty,Jessica Hullman,https://arxiv.org/pdf/1908.01697.pdf,"Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors’ acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers’ statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners’ current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.",,,,,,vimeo 360050405,,10.1109/TVCG.2019.2934287,2019,2019,Ballroom B,Tuesday,Provocations,22-Oct,3:35 PM,3:50 PM
15,SciVis,TVCG,SciVis,High-throughput feature extraction for measuring attributes of deforming open cell foams,"Steve Petruzza, Attila Gyulassy, Samuel Leventhal, Jackson Baglino, Michael Czabaj, Ashely Spears, Valerio Pascucci",,,,,,,,vimeo 359999616,,,2019,2019,Ballroom C,Tuesday,Scalar Topology,22-Oct,2:35 PM,2:50 PM
16,SciVis,TVCG,SciVis,Progressive Wasserstein Barycenters of Persistence Diagrams,"Jules Vidal, Joseph Budin, Julien Tierny",https://arxiv.org/pdf/1907.04565.pdf,"This paper presents an efficient algorithm for the progressive approximation of Wasserstein barycenters of persistence diagrams, with applications to the visual analysis of ensemble data. Given a set of scalar fields, our approach enables the computation of a persistence diagram which is representative of the set, and which visually conveys the number, data ranges and saliences of the main features of interest found in the set. Such representative diagrams are obtained by computing explicitly the discrete Wasserstein barycenter of the set of persistence diagrams, a notoriously computationally intensive task. In particular, we revisit efficient algorithms for Wasserstein distance approximation [12,51] to extend previous work on barycenter estimation [94]. We present a new fast algorithm, which progressively approximates the barycenter by iteratively increasing the computation accuracy as well as the number of persistent features in the output diagram. Such a progressivity drastically improves convergence in practice and allows to design an interruptible algorithm, capable of respecting computation time constraints. This enables the approximation of Wasserstein barycenters within interactive times. We present an application to ensemble clustering where we revisit the k-means algorithm to exploit our barycenters and compute, within execution time constraints, meaningful clusters of ensemble data along with their barycenter diagram. Extensive experiments on synthetic and real-life data sets report that our algorithm converges to barycenters that are qualitatively meaningful with regard to the applications, and quantitatively comparable to previous techniques, while offering an order of magnitude speedup when run until convergence (without time constraint). Our algorithm can be trivially parallelized to provide additional speedups in practice on standard workstations. We provide a lightweight C++ implementation of our approach that can be used to reproduce our results",,,,,,vimeo 360007493,,10.1109/TVCG.2019.2934256,2019,2019,Ballroom C,Tuesday,Scalar Topology,22-Oct,2:50 PM,3:05 PM
17,SciVis,TVCG,SciVis,The Effect of Data Transformations on Scalar Field Topological Analysis of High-Order FEM Solutions,"Ashok Jallepalli, Joshua A. Levine, Mike Kirby",https://arxiv.org/pdf/1907.07224.pdf,"High-order finite element methods (HO-FEM) are gaining popularity in the simulation community due to their success in solving complex flow dynamics. There is an increasing need to analyze the data produced as output by these simulations. Simultaneously, topological analysis tools are emerging as powerful methods for investigating simulation data. However, most of the current approaches to topological analysis have had limited application to HO-FEM simulation data for two reasons. First, the current topological tools are designed for linear data (polynomial degree one), but the polynomial degree of the data output by these simulations is typically higher (routinely up to polynomial degree six). Second, the simulation data and derived quantities of the simulation data have discontinuities at element boundaries, and these discontinuities do not match the input requirements for the topological tools. One solution to both issues is to transform the high-order data to achieve low-order, continuous inputs for topological analysis. Nevertheless, there has been little work evaluating the possible transformation choices and their downstream effect on the topological analysis. We perform an empirical study to evaluate two commonly used data transformation methodologies along with the recently introduced L-SIAC filter for processing high-order simulation data. Our results show diverse behaviors are possible. We offer some guidance about how best to consider a pipeline of topological analysis of HO-FEM simulations with the currently available implementations of topological analysis.",,,,,,vimeo 359999206,,10.1109/TVCG.2019.2934338,2019,2019,Ballroom C,Tuesday,Scalar Topology,22-Oct,3:05 PM,3:20 PM
18,SciVis,TVCG,SciVis,Toward Localized Topological Data Structures: Querying the Forest for the Tree,"Pavol Klacansky, Attila Gyulassy, Peer-Timo Bremer, Valerio Pascucci",,,,,,,,vimeo 359998742,,10.1109/TVCG.2019.2934257,2019,2019,Ballroom C,Tuesday,Scalar Topology,22-Oct,3:20 PM,3:35 PM
19,TVCG,TVCG,SciVis,Edit Distance between Merge Trees,"Raghavendra Sridharamurthy, Talha Bin Masood, Adhitya Kamakshidasan, Vijay Natarajan",,,,,,,,vimeo 364568965,,10.1109/TVCG.2018.2873612,?,2019,Ballroom C,Tuesday,Scalar Topology,22-Oct,3:35 PM,3:50 PM
20,InfoVis,TVCG,InfoVis,Construct-A-Vis: Free-Form Visualization Creation for Children,"Fearn Bishop, Johannes Zagermann, Ulrike Pfeil, Gemma Sanderson, Harald Reiterer, Uta Hinrichs",https://research-repository.st-andrews.ac.uk/bitstream/handle/10023/18228/Construct_A_Vis_InfoVis_2019.pdf,"Building data analysis skills is part of modern elementary school curricula. Recent research has explored how to facilitate children's understanding of visual data representations through completion exercises which highlight links between concrete and abstract mappings. This approach scaffolds visualization activities by presenting a target visualization to children. But how can we engage children in more free-form visual data mapping exercises that are driven by their own mapping ideas? How can we scaffold a creative exploration of visualization techniques and mapping possibilities? We present Construct-A-Vis, a tablet-based tool designed to explore the feasibility of free-form and constructive visualization activities with elementary school children. Construct-A-Vis provides adjustable levels of scaffolding visual mapping processes. It can be used by children individually or as part of collaborative activities. Findings from a study with elementary school children using Construct-A-Vis individually and in pairs highlight the potential of this free-form constructive approach, as visible in children's diverse visualization outcomes and their critical engagement with the data and mapping processes. Based on our study ndings we contribute insights into the design of free-form visualization tools for children, including the role of tool-based scaffolding mechanisms and shared interactions to guide visualization activities with children.",,,,,,vimeo 360050203,,,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,2:20 PM,2:35 PM
21,InfoVis,TVCG,InfoVis,Critical Reflections of Visualization Authoring Systems,"Arvind Satyanarayan, Bongshin Lee, Donghao Ren, Jeffrey Heer, John Stasko, John R Thompson, Matthew Brehmer, Zhicheng Liu",https://arxiv.org/pdf/1907.13568.pdf,"An emerging generation of visualization authoring systems support expressive information visualization without textual programming. As they vary in their visualization models, system architectures, and user interfaces, it is challenging to directly compare these systems using traditional evaluative methods. Recognizing the value of contextualizing our decisions in the broader design space, we present critical reflections on three systems we developed— Lyra, Data Illustrator, and Charticulator. This paper surfaces knowledge that would have been daunting within the constituent papers of these three systems. We compare and contrast their (previously unmentioned) limitations and trade-offs between expressivity and learnability. We also reflect on common assumptions that we made during the development of our systems, thereby informing future research directions in visualization authoring systems.",,,,,,,,,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,2:35 PM,2:50 PM
22,InfoVis,TVCG,InfoVis,Decoding Complex Visualizations in Science Museums – An Empirical Study,"Joyce Ma, Kwan-Liu Ma, Jennifer Frazier",https://arxiv.org/pdf/1907.13193.pdf,"This study describes a detailed analysis of museum visitors’ decoding process as they used a visualization designed to support exploration of a large, complex dataset. Quantitative and qualitative analyses revealed that it took, on average, 43 seconds for visitors to decode enough of the visualization to see patterns and relationships in the underlying data represented, and 54 seconds to arrive at their first correct data interpretation. Furthermore, visitors decoded throughout and not only upon initial use of the visualization. The study analyzed think-aloud data to identify issues visitors had mapping the visual representations to their intended referents, examine why they occurred, and consider if and how these decoding issues were resolved. The paper also describes how multiple visual encodings both helped and hindered decoding and concludes with implications on the design and adaptation of visualizations for informal science learning venues.",,,,,,,,,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,2:50 PM,3:05 PM
23,InfoVis,TVCG,InfoVis,Investigating Direct Manipulation of Graphical Encodings as a Method for User Interaction,"Bahador Saket, Samuel Huron, Charles Perin, Alex Endert",https://arxiv.org/pdf/1908.00679.pdf,"We investigate direct manipulation of graphical encodings as a method for interacting with visualizations. There is an increasing interest in developing visualization tools that enable users to perform operations by directly manipulating graphical encodings rather than external widgets such as checkboxes and sliders. Designers of such tools must decide which direct manipulation operations should be supported, and identify how each operation can be invoked. However, we lack empirical guidelines for how people convey their intended operations using direct manipulation of graphical encodings. We address this issue by conducting a qualitative study that examines how participants perform 15 operations using direct manipulation of standard graphical encodings. From this study, we 1) identify a list of strategies people employ to perform each operation, 2) observe commonalities in strategies across operations, and 3) derive implications to help designers leverage direct manipulation of graphical encoding as a method for user interaction.",,,https://github.com/encodingstudy/encodingstudy.github.io/tree/master/Study%20Tool,,,vimeo 360445782,,,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,3:05 PM,3:20 PM
24,SciVis,TVCG,SciVis,Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations,"Seth A Johnson, Francesca Samsel, Greg Abram, Daniel Olson, Andrew Solis, Bridger Herman, Philip Wolfram, Christophe Langlet, Daniel F. Keefe",https://arxiv.org/pdf/1907.13178.pdf,"We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.",,,,,,vimeo 359998878,,10.1109/TVCG.2019.2934260,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,3:20 PM,3:35 PM
25,VAST,VAST,VAST,Origraph: Interactive Network Wrangling,"Alex Bigelow, Carolina Nobre, Miriah Meyer, Alexander Lex",https://arxiv.org/pdf/1812.06337.pdf,"Networks are a natural way of thinking about many datasets. The data on which a network is based, however, is rarely collected in a form that suits the analysis process, making it necessary to create and reshape networks. Data wrangling is widely acknowledged to be a critical part of the data analysis pipeline, yet interactive network wrangling has received little attention in the visualization research community. In this paper, we discuss a set of operations that are important for wrangling network datasets and introduce a visual data wrangling tool, Origraph, that enables analysts to apply these operations to their datasets. Key operations include creating a network from source data such as tables, reshaping a network by introducing new node or edge classes, filtering nodes or edges, and deriving new node or edge attributes. Our tool, Origraph, enables analysts to execute these operations with little to no programming, and to immediately visualize the results. Origraph provides views to investigate the network model, a sample of the network, and node and edge attributes. In addition, we introduce interfaces designed to aid analysts in specifying arguments for sensible network wrangling operations. We demonstrate the usefulness of Origraph in two Use Cases: first, we investigate gender bias in the film industry, and then the influence of money on the political support for the war in Yemen.",https://origraph.github.io/,,,,https://github.com/origraph/origraph.github.io,vimeo 360154783,,,2019,2019,Ballroom A,Wednesday,(De)Construction,23-Oct,3:35 PM,3:50 PM
26,InfoVis,TVCG,InfoVis,A Comparative Evaluation of Animation and Small Multiples for Trend Visualization on Mobile Phones,"Matthew Brehmer, Bongshin Lee, Petra Isenberg, Eun Kyoung Choe",https://arxiv.org/pdf/1907.03919.pdf,"We compare the efficacy of animated and small multiples variants of scatterplots on mobile phones for comparing trends in multivariate datasets. Visualization is increasingly prevalent in mobile applications and mobile-first websites, yet there is little prior visualization research dedicated to small displays. In this paper, we build upon previous experimental research carried out on larger displays that assessed animated and non-animated variants of scatterplots. Incorporating similar experimental stimuli and tasks, we conducted an experiment where 96 crowdworker participants performed nine trend comparison tasks using their mobile phones. We found that those using a small multiples design consistently completed tasks in less time, albeit with slightly less confidence than those using an animated design. The accuracy results were more task-dependent, and we further interpret our results according to the characteristics of the individual tasks, with a specific focus on the trajectories of target and distractor data items in each task. We identify cases that appear to favor either animation or small multiples, providing new questions for further experimental research and implications for visualization design on mobile devices. Lastly, we provide a reflection on our evaluation methodology",,,https://github.com/Microsoft/MobileTrendVis,https://github.com/microsoft/MobileTrendVis/tree/master/data_analysis/1217_data,https://github.com/microsoft/MobileTrendVis/tree/master/data_analysis,vimeo 360049784,,10.1109/TVCG.2019.2934397,2019,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,10:50 AM,11:05 AM
27,InfoVis,TVCG,InfoVis,A Comparison of Visualizations for Identifying Correlation Over Time and Space,"Vanessa Peña-Araya, Emmanuel Pietriga, Anastasia Bezerianos",https://arxiv.org/pdf/1907.06399.pdf,"Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization’s effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation.",,,http://ilda.saclay.inria.fr/spacetimecorr/,http://ilda.saclay.inria.fr/spacetimecorr/experiment/,http://ilda.saclay.inria.fr/spacetimecorr/analysis/,vimeo 360050071,,,2019,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,11:05 AM,11:20 AM
28,InfoVis,TVCG,InfoVis,Common Fate for Animated Transitions in Visualization,"Amira Chalbi, Jacob Ritchie, Deokgun Park, Jungu Choi, Nicolas Roussel, Niklas Elmqvist, Fanny Chevalier",https://osf.io/zsv9t/,"The Law of Common Fate from Gestalt psychology states that visual objects moving with the same velocity along paralleltrajectories will be perceived by a human observer as grouped.  However, the concept ofcommon fateis much broader than merevelocity; in this paper we explore how common fate results from coordinated changes in luminance and size. We present results froma crowdsourced graphical perception study where we asked workers to make perceptual judgments on a series of trials involving fourgraphical objects under the influence of conflicting static and dynamic visual factors (position, size and luminance) used in conjunction.Our results yield the following rankings for visual grouping: motion>(dynamic luminance, size, luminance); dynamic size>(dynamicluminance, position); and dynamic luminance>size. We also conducted a follow-up experiment to evaluate the three dynamic visualfactors in a more ecologically valid setting, using both a Gapminder-like animated scatterplot and a thematic map of election data.The results indicate that in practice the relative grouping strengths of these factors may depend on various parameters including thevisualization characteristics and the underlying data. We discuss design implications for animated transitions in data visualization.",,,https://osf.io/3zkhv/,https://osf.io/3zkhv/,https://osf.io/3zkhv/,vimeo 360484281,,10.1109/TVCG.2019.2934288,2019,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,11:20 AM,11:35 AM
29,VAST,TVCG,VAST,CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics,"Thomas E. Polk, Dominik Jäckle, Johannes Häußler, Jing Yang",https://kops.uni-konstanz.de/bitstream/handle/123456789/46446/CourtTime__Generating_Actionable_Insights_into_Amateur_Tennis_Matches_Using_Visual_Analytics%20%28with%20acknowledgements%29.pdf?sequence=1&isAllowed=y,"Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1-D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches.",,,,,,vimeo 360155110,,10.1109/TVCG.2019.2934243,2019,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,11:35 AM,11:50 AM
30,VAST,TVCG,VAST,Tac-Simur: Visual Analytics for Tactic-based Match Simulation of Table Tennis,"Jiachen Wang, Kejian Zhao, Dazhen Deng, Anqi Cao, Xiao Xie, Zheng Zhou, Hui Zhang, Yingcai Wu",,,,,,,,vimeo 360154177,,,2019,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,11:50 AM,12:05 PM
31,TVCG,TVCG,VAST,COPE: Interactive Exploration of Co-occurrence Patterns in Spatial Time Series,"Jie Li, Siming Chen, Kang Zhang, Gennady Andrienko, Natalia Andrienko",http://openaccess.city.ac.uk/id/eprint/20131/1/V1.63%20minor%20review-final.pdf,"Spatial time series is a common type of data dealt with in many domains, such as economic statistics and environmental science. There have been many studies focusing on finding and analyzing various kinds of events in time series; the term ‘event’ refers to significant changes or occurrences of particular patterns formed by consecutive attribute values. We focus on a further step in event analysis: discover temporal relationship patterns between event locations, i.e., repeated cases when there is a specific temporal relationship (same time, before, or after) between events occurring at two locations. This can provide important clues for understanding the formation and spreading mechanisms of events and interdependencies among spatial locations. We propose a visual exploration framework COPE (Co-Occurrence Pattern Exploration), which allows users to extract events of interest from data and detect various co-occurrence patterns among them. Case studies and expert reviews were conducted to verify the effectiveness and scalability of COPE using two real-world datasets.",,,,,,vimeo 364567978,,,?,2019,Ballroom B,Wednesday,Animation and Sports,23-Oct,12:05 PM,12:20 PM
32,InfoVis,TVCG,InfoVis,"Biased Average Position Estimates in Line and Bar Graphs: Underestimation, Overestimation, and Perceptual Pull","Cindy Xiong, Cristina R Ceja, Casimir Ludwig, Steven Franconeri",https://arxiv.org/pdf/1908.00073.pdf,"In visual depictions of data, position (i.e., the vertical height of a line or a bar) is believed to be the most precise way to encode information compared to other encodings (e.g., hue). Not only are other encodings less precise than position, but they can also be prone to systematic biases (e.g., color category boundaries can distort perceived differences between hues). By comparison, position’s high level of precision may seem to protect it from such biases. In contrast, across three empirical studies, we show that while position may be a precise form of data encoding, it can also produce systematic biases in how values are visually encoded, at least for reports of average position across a short delay. In displays with a single line or a single set of bars, reports of average positions were significantly biased, such that line positions were underestimated and bar positions were overestimated. In displays with multiple data series (i.e., multiple lines and/or sets of bars), this systematic bias still persisted. We also observed an effect of “perceptual pull”, where the average position estimate for each series was ‘pulled’ toward the other. These findings suggest that, although position may still be the most precise form of visual data encoding, it can also be systematically biased.",,,,,,vimeo 360049835,,10.1109/TVCG.2019.2934400,2019,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,4:10 PM,4:25 PM
33,InfoVis,TVCG,InfoVis,Measures of the benefit of direct encoding of data deltas for data pair relation perception,"Christine Nothelfer, Steven Franconeri",https://osf.io/jup9a,"The power of data visualization is not to convey absolute values of individual data points, but to allow the exploration of relations (increases or decreases in a data value) among them. One approach to highlighting these relations is to explicitly encode the numeric differences (deltas) between data values. Because this approach removes the context of the individual data values, it is important to measure how much of a performance improvement it actually offers, especially across differences in encodings and tasks, to ensure that it is worth adding to a visualization design. Across 3 different tasks, we measured the increase in visual processing efficiency for judging the relations between pairs of data values, from when only the values were shown, to when the deltas between the values were explicitly encoded, across position and length visual feature encodings (and slope encodings in Experiments 1 & 2). In Experiment 1, the participant’s task was to locate a pair of data values with a given relation (e.g., Find the ‘small bar to the left of a tall bar’ pair) among pairs of the opposite relation, and we measured processing efficiency from the increase in response times as the number of pairs increased. In Experiment 2, the task was to judge which of two relation types was more prevalent in a briefly presented display of 10 data pairs (e.g., Are there more ‘small bar to the left of a tall bar’ pairs or more ‘tall bar to the left of a small bar’ pairs?). In the final experiment, the task was to estimate the average delta within a briefly presented display of 6 data pairs (e.g., What is the average bar height difference across all ‘small bar to the left of a tall bar’ pairs?). Across all three experiments, visual processing of relations between data value pairs was significantly better when directly encoded as deltas rather than implicitly between individual data points, and varied substantially depending on the task (improvement ranged from 25% to 95%). Considering the ubiquity of bar charts and dot plots, relation perception for individual data values is highly inefficient, and confirms the need for alternative designs that provide not only absolute values, but also direct encoding of critical relationships between those values.",,,,,,vimeo 360049981,,,2019,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,4:25 PM,4:40 PM
34,TVCG,TVCG,InfoVis,A Task-based Taxonomy of Cognitive Biases for Information Visualization,"Evanthia Dimara, Steven Franconeri, Catherine Plaisant, Anastasia Bezerianos, Pierre Dragicevic",https://hal.sorbonne-universite.fr/hal-01868738v2/document,"Information visualization designers strive to design data displays that allow for efficient exploration, analysis, and communication of patterns in data, leading to informed decisions. Unfortunately, human judgment and decision making are imperfect and often plagued by cognitive biases. There is limited empirical research documenting how these biases affect visual data analysis activities. Existing taxonomies are organized by cognitive theories that are hard to associate with visualization tasks. Based on a survey of the literature we propose a task-based taxonomy of 154 cognitive biases organized in 7 main categories. We hope the taxonomy will help visualization researchers relate their design to the corresponding possible biases, and lead to new research that detects and addresses biased judgment and decision making in data visualization.",,,,,,vimeo 364568413,,10.1109/TVCG.2018.2872577,?,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,4:40 PM,4:55 PM
35,TVCG,TVCG,InfoVis,The Curse of Knowledge in Visual Data Communication,"Cindy Xiong, Lisanne van Weelden, Steven Franconeri",https://osf.io/xc7e8,"A viewer can extract many potential patterns from any set of visualized data values. But that means that two people can see different patterns in the same visualization, potentially leading to miscommunication. Here, we show that when people are primed to see one pattern in the data as visually salient, they believe that naïve viewers will experience the same visual salience. Participants were told one of multiple backstories about political events that affected public polling data, before viewing a graph that depicted those data. One pattern in the data was particularly visually salient to them given the backstory that they heard. They then predicted what naïve viewers would most visually salient on the visualization. They were strongly influenced by their own knowledge, despite explicit instructions to ignore it, predicting that others would find the same patterns to be most visually salient. This result reflects a psychological phenomenon known as the curse of knowledge, where an expert struggles to re-create the state of mind of a novice. The present findings show that the curse of knowledge also plagues the visual perception of data, explaining why people can fail to connect with audiences when they communicate patterns in data.",,,http://visualthinking.psych.northwestern.edu/VisualizationCurse2018/Stimulus/,http://visualthinking.psych.northwestern.edu/VisualizationCurse2018/Results/,,vimeo 364568644,,10.1109/TVCG.2019.2917689,?,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,4:55 PM,5:10 PM
36,VAST,TVCG,VAST,Evaluating Perceptual Bias During Geometric Scaling of Scatterplots,"Yating Wei, Honghui Mei, Ying Zhao, Shuyue Zhou, Bingru Lin, Haojin Jiang, Wei Chen",https://arxiv.org/pdf/1908.00403.pdf,"Scatterplots are frequently scaled to fit display areas in multi-view and multi-device data analysis environments. A common method used for scaling is to enlarge or shrink the entire scatterplot together with the inside points synchronously and proportionally. This process is called geometric scaling. However, geometric scaling of scatterplots may cause a perceptual bias, that is, the perceived and physical values of visual features may be dissociated with respect to geometric scaling. For example, if a scatterplot is projected from a laptop to a large projector screen, then observers may feel that the scatterplot shown on the projector has fewer points than that viewed on the laptop. This paper presents an evaluation study on the perceptual bias of visual features in scatterplots caused by geometric scaling. The study focuses on three fundamental visual features (i.e., numerosity, correlation, and cluster separation) and three hypotheses that are formulated on the basis of our experience. We carefully design three controlled experiments by using well-prepared synthetic data and recruit participants to complete the experiments on the basis of their subjective experience. With a detailed analysis of the experimental results, we obtain a set of instructive findings. First, geometric scaling causes a bias that has a linear relationship with the scale ratio. Second, no significant difference exists between the biases measured from normally and uniformly distributed scatterplots. Third, changing the point radius can correct the bias to a certain extent. These findings can be used to inspire the design decisions of scatterplots in various scenarios.",,,,,,vimeo 360154646,,10.1109/TVCG.2019.2934208,2019,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,5:10 PM,5:25 PM
37,VAST,VAST,VAST,FDive: Learning Relevance Models using Pattern-based Similarity Measures,"Frederik L. Dennig, Thomas E. Polk, Zudi Lin, Tobias Schreck, Hanspeter Pfister, Michael Behrisch",https://arxiv.org/pdf/1907.12489.pdf,"The detection of interesting patterns in large high-dimensional datasets is difficult because of their dimensionality and pattern complexity. Therefore, analysts require automated support for the extraction of relevant patterns. In this paper, we present FDIVE, a visual active learning system that helps to create visually explorable relevance models, assisted by learning a pattern-based similarity. We use a small set of user-provided labels to rank similarity measures, consisting of feature descriptor and distance function combinations, by their ability to distinguish relevant from irrelevant data. Based on the best-ranked similarity measure, the system calculates an interactive Self-Organizing Map-based relevance model, which classifies data according to the cluster affiliation. It also automatically prompts further relevance feedback to improve its accuracy. Uncertain areas, especially near the decision boundaries, are highlighted and can be refined by the user. We evaluate our approach by comparison to state-of-the-art feature selection techniques and demonstrate the usefulness of our approach by a case study classifying electron microscopy images of brain cells. The results show that FDIVE enhances both the quality and understanding of relevance models and can thus lead to new insights for brain research.",,,,,,vimeo 360155013,,,2019,2019,Ballroom C,Tuesday,Bias & Patterns,22-Oct,5:25 PM,5:40 PM
38,InfoVis,TVCG,InfoVis,Color Crafting: Automating the Construction of Designer Quality Color Ramps,"Stephen Smart, Keke Wu, Danielle Albers Szafir",https://arxiv.org/pdf/1908.00629.pdf,"Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color. We do this using an algorithmic approach that models designer practices by analyzing patterns in the structure of designer-crafted color ramps. We construct these models from a corpus of 222 expert-designed color ramps, and use the results to automatically generate ramps that mimic designer practices. We evaluate our approach through an empirical study comparing the outputs of our approach with designer-crafted color ramps. Our models produce ramps that support accurate and aesthetically pleasing visualizations at least as well as designer ramps and that outperform conventional mathematical approaches.",,,https://osf.io/b5wjc/,https://osf.io/b5wjc/,,vimeo 360050339,,10.1109/TVCG.2019.2934284,2019,2019,Ballroom B,Friday,Color,25-Oct,9:00 AM,9:15 AM
39,InfoVis,TVCG,InfoVis,Estimating color-concept associations from image statistics,"Ragini Rathore, Zachary Leggon, Laurent Lessard, Karen Schloss",https://arxiv.org/pdf/1908.00220.pdf,"To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people’s expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color.",,,,,,vimeo 360050505,,,2019,2019,Ballroom B,Friday,Color,25-Oct,9:15 AM,9:30 AM
40,TVCG,TVCG,InfoVis,The Effect of Color Scales on Climate Scientists’ Objective and Subjective Performance in Spatial Data Analysis Tasks,"Aritra Dasgupta, Jorge Poco, Bernice Rogowitz, Kyungsik Han, Enrico Bertini, Claudio T. Silva",,,,,,,,vimeo 364568438,,,?,2019,Ballroom B,Friday,Color,25-Oct,9:30 AM,9:45 AM
41,TVCG,TVCG,SciVis,Measuring and Modeling the Feature Detection Threshold Functions of Colormaps,"Colin Ware, Terece L. Turton, Roxana Bujack, Francesca Samsel, Piyush Shrivastava, David H. Rogers",,,,,,,,vimeo 364569128,,,?,2019,Ballroom B,Friday,Color,25-Oct,9:45 AM,10:00 AM
42,TVCG,TVCG,SciVis,Measuring the Effects of Scalar and Spherical Colormaps on Ensembles of DMRI Tubes,"Jian Chen, Guohao Zhang, Wesley Chiou, David H. Laidlaw, Alexander P. Auchus",https://arxiv.org/pdf/1810.07882.pdf,"We report empirical study results on the color encoding of ensemble scalar and orientation to visualize diffusion magnetic resonance imaging (DMRI) tubes. The experiment tested six scalar colormaps for average fractional anisotropy (FA) tasks (grayscale, blackbody, diverging, isoluminant-rainbow, extended-blackbody, and coolwarm) and four three-dimensional (3D) directional encodings for tract tracing tasks (uniform gray, absolute, eigenmap, and Boy’s surface embedding). We found that extended-blackbody, coolwarm, and blackbody remain the best three approaches for identifying ensemble average in 3D. Isoluminant-rainbow coloring led to the same ensemble mean accuracy as other colormaps. However, more than 50% of the answers consistently had higher estimates of the ensemble average, independent of the mean values. Hue, not luminance, influences ensemble estimates of mean values. For ensemble orientation-tracing tasks, we found that the Boy’s surface embedding (greatest spatial resolution and contrast) and absolute color (lowest spatial resolution and contrast) schemes led to more accurate answers than the eigenmaps scheme (medium resolution and contrast), acting as the uncanny-valley phenomenon of visualization design in terms of accuracy",,,,,,vimeo 365399042,,10.1109/TVCG.2019.2898438,?,2019,Ballroom B,Friday,Color,25-Oct,10:00 AM,10:15 AM
43,InfoVis,TVCG,InfoVis,A Deep Generative Model for Graph Layout,"Oh-Hyun Kwon, Kwan-Liu Ma",https://arxiv.org/pdf/1904.12225.pdf,"Different layouts can characterize different aspects of the same graph. Finding a “good” layout of a graph is thus an important task for graph visualization. In practice, users often visualize a graph in multiple layouts by using different methods and varying parameter settings until they find a layout that best suits the purpose of the visualization. However, this trial-and-error process is often haphazard and time-consuming. To provide users with an intuitive way to navigate the layout design space, we present a technique to systematically visualize a graph in diverse layouts using deep generative models. We design an encoder-decoder architecture to learn a model from a collection of example layouts, where the encoder represents training examples in a latent space and the decoder produces layouts from the latent space. In particular, we train the model to construct a two-dimensional latent space for users to easily explore and generate various layouts. We demonstrate our approach through quantitative and qualitative evaluations of the generated layouts. The results of our evaluations show that our model is capable of learning and generalizing abstract concepts of graph layouts, not just memorizing the training examples. In summary, this paper presents a fundamentally new approach to graph visualization where a machine learning model learns to visualize a graph from examples without manually-defined heuristics.",http://kwonoh.net/dgl/,,,,,vimeo 360049688,,10.1109/TVCG.2019.2934396,2019,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,9:00 AM,9:15 AM
44,InfoVis,TVCG,InfoVis,DeepDrawing: A Deep Learning Approach to Graph Drawing,"Yong Wang, Zhihua Jin, Qianwen Wang, Weiwei Cui, Tengfei Ma, Huamin Qu",https://arxiv.org/pdf/1907.11040.pdf,"Node-link diagrams are widely used to facilitate network explorations. However, when using a graph drawing technique to visualize networks, users often need to tune different algorithm-specific parameters iteratively by comparing the corresponding drawing results in order to achieve a desired visual effect. This trial and error process is often tedious and time-consuming, especially for non-expert users. Inspired by the powerful data modelling and prediction capabilities of deep learning techniques, we explore the possibility of applying deep learning techniques to graph drawing. Specifically, we propose using a graph-LSTM-based approach to directly map network structures to graph drawings. Given a set of layout examples as the training dataset, we train the proposed graph-LSTM-based model to capture their layout characteristics. Then, the trained model is used to generate graph drawings in a similar style for new networks. We evaluated the proposed approach on two special types of layouts (i.e., grid layouts and star layouts) and two general types of layouts (i.e., ForceAtlas2 and PivotMDS) in both qualitative and quantitative ways. The results provide support for the effectiveness of our approach. We also conducted a time cost assessment on the drawings of small graphs with 20 to 50 nodes. We further report the lessons we learned and discuss the limitations and future work.",,,,,,vimeo 360049919,,10.1109/TVCG.2019.2934798,2019,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,9:15 AM,9:30 AM
45,InfoVis,TVCG,InfoVis,Interactive Structure-aware Blending of Diverse Edge Bundling Visualizations,"Yunhai Wang, Mingliang Xue, Yanyan Wang, Xinyuan Yan, Baoquan Chen, Chi-Wing Fu, Christophe Hurter",,,,,,,,vimeo 360050223,,10.1109/TVCG.2019.2934805,2019,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,9:30 AM,9:45 AM
46,InfoVis,TVCG,InfoVis,Persistent Homology Guided Force-Directed Graph Layouts,"Ashley Suh, Mustafa Hajij, Bei Wang, Carlos Scheidegger, Paul Rosen",https://arxiv.org/pdf/1712.05548.pdf,"Graphs are commonly used to encode relationships among entities, yet their abstractness makes them difficult to analyze. Node-link diagrams are popular for drawing graphs, and force-directed layouts provide a flexible method for node arrangements that use local relationships in an attempt to reveal the global shape of the graph. However, clutter and overlap of unrelated structures can lead to confusing graph visualizations. This paper leverages the persistent homology features of an undirected graph as derived information for interactive manipulation of force-directed layouts. We first discuss how to efficiently extract 0-dimensional persistent homology features from both weighted and unweighted undirected graphs. We then introduce the interactive persistence barcode used to manipulate the force-directed graph layout. In particular, the user adds and removes contracting and repulsing forces generated by the persistent homology features, eventually selecting the set of persistent homology features that most improve the layout. Finally, we demonstrate the utility of our approach across a variety of synthetic and real datasets",,,,,,vimeo 360050009,,,2019,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,9:45 AM,10:00 AM
47,TVCG,TVCG,InfoVis,Graph Drawing by Stochastic Gradient Descent,"Jonathan X. Zheng, Samraat Pawar, Dan F. M. Goodman",https://arxiv.org/pdf/1710.04626.pdf,"A popular method of force-directed graph drawing is multidimensional scaling using graph-theoretic distances as input. We present an algorithm to minimize its energy function, known as stress, by using stochastic gradient descent (SGD) to move a single pair of vertices at a time. Our results show that SGD can reach lower stress levels faster and more consistently than majorization, without needing help from a good initialization. We then show how the unique properties of SGD make it easier to produce constrained layouts than previous approaches. We also show how SGD can be directly applied within the sparse stress approximation of Ortmann et al. [1], making the algorithm scalable up to large graphs.",,,,,https://github.com/jxz12/s_gd2,vimeo 364569741,,,?,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,10:00 AM,10:15 AM
48,TVCG,TVCG,VAST,The Effect of Edge Bundling and Seriation on Sensemaking of Biclusters in Bipartite Graphs,"Maoyuan Sun, Jian Zhao, Hao Wu, Kurt Luther, Chris North, Naren Ramakrishnan",,,,,,,,vimeo 364567994,,,?,2019,Ballroom B,Wednesday,Drawing Nodes and Edges,23-Oct,10:15 AM,10:30 AM
49,InfoVis,TVCG,InfoVis,Uncertainty-Aware Principal Component Analysis,"Jochen Görtler, Thilo Spinner, Dirk Streeb, Daniel Weiskopf, Oliver Deussen",https://arxiv.org/pdf/1905.01127.pdf,"We present a technique to perform dimensionality reduction on data that is subject to uncertainty. Our method is a generalization of traditional principal component analysis (PCA) to multivariate probability distributions. In comparison to non-linear methods, linear dimensionality reduction techniques have the advantage that the characteristics of such probability distributions remain intact after projection. We derive a representation of the PCA sample covariance matrix that respects potential uncertainty in each of the inputs, building the mathematical foundation of our new method: uncertainty-aware PCA. In addition to the accuracy and performance gained by our approach over sampling-based strategies, our formulation allows us to perform sensitivity analysis with regard to the uncertainty in the data. For this, we propose factor traces as a novel visualization that enables to better understand the influence of uncertainty on the chosen principal components. We provide multiple examples of our technique using real-world datasets. As a special case, we show how to propagate multivariate normal distributions through PCA in closed form. Furthermore, we discuss extensions and limitations of our approach.",,,,,,vimeo 360050141,,,2019,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,2:20 PM,2:35 PM
50,SciVis,TVCG,SciVis,A Structural Average of Labeled Merge Trees for Uncertainty Visualization,"Lin Yan, Yusu Wang, Elizabeth Munch, Ellen Gasparovic, Bei Wang",https://arxiv.org/pdf/1908.00113.pdf,"Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization.",,,,,,vimeo 359998912,,10.1109/TVCG.2019.2934242,2019,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,2:35 PM,2:50 PM
51,SciVis,TVCG,SciVis,Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes,"Katarina Furmanova, Adam Jurčík, Barbora Kozlikova, Helwig Hauser, Jan Byška",https://arxiv.org/pdf/1907.04112.pdf,"When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data – from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels and at each level, we offer a set of selection and filtering operations enabling the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts.",,,,,,vimeo 359999233,,10.1109/TVCG.2019.2934333,2019,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,2:50 PM,3:05 PM
52,TVCG,TVCG,SciVis,eFESTA: Ensemble Feature Exploration with Surface Density Estimates,"Wenbin He, Hanqi Guo, Han-Wei Shen, Tom Peterka",,,,,,,,vimeo 364569031,,10.1109/TVCG.2018.2879866,?,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,3:05 PM,3:20 PM
53,TVCG,TVCG,SciVis,Visualization and Visual Analysis of Ensemble Data: A Survey,"Junpeng Wang, Subhashis Hazarika, Cheng Li, Han-Wei Shen",,,,,,,,vimeo 364569796,,,?,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,3:20 PM,3:35 PM
54,TVCG,TVCG,VAST,Exploring the Sensitivity of Choropleths under Attribute Uncertainty,"Zhaosong Huang, Yafeng Lu, Elizabeth A. Mack, Wei Chen, Ross Maciejewski",,,,,,,,vimeo 364568169,,10.1109/TVCG.2019.2892483,?,2019,Ballroom A,Thursday,Ensembles & Uncertainty,24-Oct,3:35 PM,3:50 PM
55,InfoVis,TVCG,InfoVis,Toward Objective Evaluation of Working Memory in Visualizations: A Case Study Using Pupillometry and a Dual-Task Paradigm,"Lace M. K. Padilla, Spencer Castro, P. Samuel Quinan, Ian T. Ruginski, Sarah Creem-Regehr",https://osf.io/zj6tp/,"Cognitive science has established widely used and validated procedures for evaluating working memory in numerous applied domains, but surprisingly few studies have employed these methodologies to assess claims about the impacts of visualizations on working memory. The lack of information visualization research that uses validated procedures for measuring working memory may be due, in part, to the absence of cross-domain methodological guidance tailored explicitly to the unique needs of visualization research. This paper presents a set of clear, practical, and empirically validated methods for evaluating working memory during visualization tasks and provides readers with guidance in selecting an appropriate working memory evaluation paradigm. As a case study, we illustrate multiple methods for evaluating working memory in a visual-spatial aggregation task with geospatial data. The results show that the use of dual-task experimental designs (simultaneous performance of several tasks compared to single-task performance) and pupil dilation can reveal working memory demands associated with task difficulty and dual-tasking. In a dual-task experimental design, measures of task completion times and pupillometry revealed the working memory demands associated with both task difficulty and dual-tasking. Pupillometry demonstrated that participants’ pupils were significantly larger when they were completing a more difficult task and when multitasking. We propose that researchers interested in the relative differences in working memory between visualizations should consider a converging methods approach, where physiological measures and behavioral measures of working memory are employed to generate a rich evaluation of visualization effort.",,,https://osf.io/6u8em/,https://osf.io/6u8em/,https://osf.io/6u8em/,vimeo 360050392,,10.1109/TVCG.2019.2934286,2019,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,10:50 AM,11:05 AM
56,InfoVis,TVCG,InfoVis,VisTA: Towards Using Visual Analytics to Support the Investigation of Think-Aloud Sessions,"Mingming Fan, Ke Wu, Jian Zhao, Yue Li, Winter Wei, Khai Truong",,,,,,,,,,,2019,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,11:05 AM,11:20 AM
57,TVCG,TVCG,SciVis,Embedding Meta-Information into Visualizations,"Alok Hota, Jian Huang",,,,,,,,vimeo 364569334,,,?,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,11:20 AM,11:35 AM
58,TVCG,TVCG,SciVis,On Evaluating Runtime Performance of Interactive Visualizations,"Valentin Bruder, Christoph Müller, Steffen Frey, Thomas Ertl",,,,,,,,vimeo 364569107,,10.1109/TVCG.2019.2898435,?,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,11:35 AM,11:50 AM
59,VAST,TVCG,VAST,The Validity and Generalizability of Summative Evaluation Methods in Visual Analytics,"Mosab Khayat, Morteza Karimzadeh, David Ebert, Arif Ghafoor",https://arxiv.org/pdf/1907.13314.pdf,"Many evaluation methods have been used to assess the usefulness of Visual Analytics (VA) solutions. These methods stem from a variety of origins with different assumptions and goals, which cause confusion about their proofing capabilities. Moreover, the lack of discussion about the evaluation processes may limit our potential to develop new evaluation methods specialized for VA. In this paper, we present an analysis of evaluation methods that have been used to summatively evaluate VA solutions. We provide a survey and taxonomy of the evaluation methods that have appeared in the VAST literature in the past two years. We then analyze these methods in terms of validity and generalizability of their findings, as well as the feasibility of using them. We propose a new metric called summative quality to compare evaluation methods according to their ability to prove usefulness, and make recommendations for selecting evaluation methods based on their summative quality in the VA domain.",,,,,,vimeo 360155500,,,2019,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,11:50 AM,12:05 PM
60,TVCG,TVCG,VAST,An Analysis of Automated Visual Analysis Classification: Interactive Visualization Task Inference of Cancer Genomics Domain Experts,"Connor C. Gramazio, Jeff Huang, David H. Laidlaw",,,,,,,,vimeo 364568057,,,?,2019,Ballroom A,Wednesday,Evaluation & Reproducibility,23-Oct,12:05 PM,12:20 PM
61,SciVis,TVCG,SciVis,Dynamic Nested Tracking Graphs,"Jonas Lukasczyk, Christoph Garth, Tim Biedert, Ross Maciejewski, Gunther H. Weber, Heike Leitte",,,,,,,,vimeo 359999289,,,2019,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,4:10 PM,4:25 PM
62,SciVis,TVCG,SciVis,Extraction and Visual Analysis of Potential Vorticity Banners around the Alps,"Robin Bader, Michael Sprenger, Nikolina Ban, Stefan Rüdisühli, Christoph Schär, Tobias Günther",,,,,,,,vimeo 359998953,,10.1109/TVCG.2019.2934310,2019,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,4:25 PM,4:40 PM
63,SciVis,TVCG,SciVis,Multi-Scale Topological Analysis of Asymmetric Tensor Fields on Surfaces,"Fariba Khan, Lawrence Roy, Eugene Zhang, Botong Qu, Shih-Hsuan Hung, Harry Yeh, Robert S. Laramee, Yue Zhang",,,,,,,,vimeo 359999144,,10.1109/TVCG.2019.2934314,2019,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,4:40 PM,4:55 PM
64,SciVis,TVCG,SciVis,Vector Field Topology of Time-Dependent Flows in a Steady Reference Frame,"Irene Baeza Rojo, Tobias Günther",,,,,,,,vimeo 359999444,,10.1109/TVCG.2019.2934375,2019,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,4:55 PM,5:10 PM
65,TVCG,TVCG,SciVis,Feature Tracking by Two-Step Optimization,"Andrea Schnorr, Dirk N. Helmrich, Dominik Denker, Torsten W. Kuhlen, Bernd Hentschel",,,,,,,,vimeo 364569076,,10.1109/TVCG.2018.2883630,?,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,5:10 PM,5:25 PM
66,VAST,TVCG,VAST,Scalable Topological Data Analysis and Visualization for Interpreting Data-Driven Models in Scientific Applications,"Shusen Liu, Di Wang, Dan Maljovec, Rushil Anirudh, Jayaraman J. Thiagarajan, Sam Ade Jacobs, Brian C. Van Essen, David Hysom, Jae-Seung Yeom, Jim Gaffney, J. Luc Peterson, Peter B. Robinson, Harsh Bhatia, Valerio Pascucci, Brian K. Spears, Peer-Timo Bremer",https://arxiv.org/pdf/1907.08325.pdf,"With the rapid adoption of machine learning techniques for large-scale applications in science and engineering comes the convergence of two grand challenges in visualization. First, the utilization of black box models (e.g., deep neural networks) calls for advanced techniques in exploring and interpreting model behaviors. Second, the rapid growth in computing has produced enormous datasets that require techniques that can handle millions or more samples. Although some solutions to these interpretability challenges have been proposed, they typically do not scale beyond thousands of samples, nor do they provide the high-level intuition scientists are looking for. Here, we present the first scalable solution to explore and analyze high-dimensional functions often encountered in the scientific data analysis pipeline. By combining a new streaming neighborhood graph construction, the corresponding topology computation, and a novel data aggregation scheme, namely <em>topology aware datacubes</em>, we enable interactive exploration of both the topological and the geometric aspect of high-dimensional data. Following two use cases from high-energy-density (HED) physics and computational biology, we demonstrate how these capabilities have led to crucial new insights in both applications.",,,,,,vimeo 360155819,,,2019,2019,Ballroom B,Tuesday,Features and Topology,22-Oct,5:25 PM,5:40 PM
67,SciVis,TVCG,SciVis,Accelerated Monte Carlo Rendering of Finite-Time Lyapunov Exponents,"Irene Baeza Rojo, Markus Gross, Tobias Günther",,,,,,,,vimeo 359999098,,10.1109/TVCG.2019.2934313,2019,2019,Ballroom C,Wednesday,Flow,23-Oct,9:00 AM,9:15 AM
68,SciVis,TVCG,SciVis,Analysis of the Near-Wall Flow in a Turbine Cascade by Splat Visualization,"Baldwin Nsonga, Gerik Scheuermann, Stefan Gumhold, Jordi Ventosa-Molina, Denis Koschichow, Jochen Fröhlich",https://arxiv.org/pdf/1907.09904.pdf,"Turbines are essential components of jet planes and power plants. Therefore, their efficiency and service life are of central engineering interest. In the case of jet planes or thermal power plants, the heating of the turbines due to the hot gas flow is critical. Besides effective cooling, it is a major goal of engineers to minimize heat transfer between gas flow and turbine by design. Since it is known that splat events have a substantial impact on the heat transfer between flow and immersed surfaces, we adapt a splat detection and visualization method to a turbine cascade simulation in this case study. Because splat events are small phenomena, we use a direct numerical simulation resolving the turbulence in the flow as the base of our analysis. The outcome shows promising insights into splat formation and its relation to vortex structures. This may lead to better turbine design in the future.",,,,,,vimeo 359999261,,,2019,2019,Ballroom C,Wednesday,Flow,23-Oct,9:15 AM,9:30 AM
69,TVCG,TVCG,SciVis,Detection and Visualization of Splat and Antisplat Events in Turbulent Flows,"Baldwin Nsonga, Martin Niemann, Jochen Fröhlich, Joachim Staib, Stefan Gumhold, Gerik Scheuermann",,,,,,,,vimeo 364569430,,10.1109/TVCG.2019.2920157,?,2019,Ballroom C,Wednesday,Flow,23-Oct,9:30 AM,9:45 AM
70,TVCG,TVCG,SciVis,Extreme-Scale Stochastic Particle Tracing for Uncertain Unsteady Flow Visualization and Analysis,"Hanqi Guo, Wenbin He, Sangmin Seo, Han-Wei Shen, Emil Mihai Constantinescu, Chunhui Liu, Tom Peterka",,,,,,,,vimeo 364568821,,,?,2019,Ballroom C,Wednesday,Flow,23-Oct,9:45 AM,10:00 AM
71,TVCG,TVCG,SciVis,FlowNet: A Deep Learning Framework for Clustering and Selection of Streamlines and Stream Surfaces,"Jun Han, Jun Tao, Chaoli Wang",,,,,,,,vimeo 364569054,,10.1109/TVCG.2018.2880207,?,2019,Ballroom C,Wednesday,Flow,23-Oct,10:00 AM,10:15 AM
72,TVCG,TVCG,SciVis,Hyper-Objective Vortices,"Tobias Günther, Holger Theisel",,,,,,,,vimeo 364568933,,10.1109/TVCG.2018.2868760,?,2019,Ballroom C,Wednesday,Flow,23-Oct,10:15 AM,10:30 AM
73,TVCG,TVCG,VAST,"A Visual Analytics System for Exploring, Monitoring, and Forecasting Road Traffic Congestion","Chunggi Lee, Yeonjun Kim, Seungmin Jin, Dongmin Kim, Ross Maciejewski, David Ebert, Sungahn Ko",,,,,,,,vimeo 364568300,,10.1109/TVCG.2019.2922597,?,2019,Ballroom C,Thursday,Geovisualization,24-Oct,2:20 PM,2:35 PM
74,InfoVis,TVCG,InfoVis,SmartCube: An Adaptive Data Management Architecture for the Real-Time Visualization of Spatiotemporal Datasets,"Can Liu, Cong Wu, Hanning Shao, Xiaoru Yuan",,,,,,,,vimeo 360050463,,,2019,2019,Ballroom C,Thursday,Geovisualization,24-Oct,2:35 PM,2:50 PM
75,TVCG,TVCG,SciVis,Real-Time Exploration of Large Spatiotemporal Datasets based on Order Statistics,"Cícero L. Pahins, Nivan Ferreira, João L. Comba",,,,,,,,vimeo 364569181,,10.1109/TVCG.2019.2914446,?,2019,Ballroom C,Thursday,Geovisualization,24-Oct,2:50 PM,3:05 PM
76,VAST,TVCG,VAST,AirVis: Visual Analytics of Air Pollution Propagation,"Zikun Deng, Di Weng, Jiahui Chen, Ren Liu, Zhibin Wang, Jie Bao, Yu Zheng, Yingcai Wu",,,,,,,,vimeo 360154598,,10.1109/TVCG.2019.2934670,2019,2019,Ballroom C,Thursday,Geovisualization,24-Oct,3:05 PM,3:20 PM
77,VAST,TVCG,VAST,OD Morphing: balancing simplicity with faithfulness for OD bundling,"Yan Lyu, Xu Liu, Hanyi Chen, Arpan Mangal, Brian Lim, Kai Liu, Chao Chen",,,,,,,,vimeo 360154344,,,2019,2019,Ballroom C,Thursday,Geovisualization,24-Oct,3:20 PM,3:35 PM
78,TVCG,TVCG,VAST,Semantics-Space-Time Cube: A Conceptual Framework for Systematic Analysis of Texts in Space and Time,"Jie Li, Siming Chen, Wei Chen, Gennady Andrienko, Natalia Andrienko",http://openaccess.city.ac.uk/id/eprint/21109/1/semantics-space-time.R1.pdf,"We propose an approach to analyzing data in which texts are associated with spatial and temporal references with the aim to understand how the text semantics vary over space and time. To represent the semantics, we apply probabilistic topic modeling. After extracting a set of topics and representing the texts by vectors of topic weights, we aggregate the data into a data cube with the dimensions corresponding to the set of topics, the set of spatial locations (e.g., regions), and the time divided into suitable intervals according to the scale of the planned analysis. Each cube cell corresponds to a combination (topic, location, time interval) and contains aggregate measures characterizing the subset of the texts concerning this topic and having the spatial and temporal references within these location and interval. Based on this structure, we systematically describe the space of analysis tasks on exploring the interrelationships among the three heterogeneous information facets, semantics, space, and time. We introduce the operations of projecting and slicing the cube, which are used to decompose complex tasks into simpler subtasks. We then present a design of a visual analytics system intended to support these subtasks. To reduce the complexity of the user interface, we apply the principles of structural, visual, and operational uniformity while respecting the specific properties of each facet. The aggregated data are represented in three parallel views corresponding to the three facets and providing different complementary perspectives on the data. The views have similar look-and-feel to the extent allowed by the facet specifics. Uniform interactive operations applicable to any view support establishing links between the facets. The uniformity principle is also applied in supporting the projecting and slicing operations on the data cube. We evaluate the feasibility and utility of the approach by applying it in two analysis scenarios using geolocated social media data for studying people’s reactions to social and natural events of different spatial and temporal scales.",,,,,,vimeo 364568102,,,?,2019,Ballroom C,Thursday,Geovisualization,24-Oct,3:35 PM,3:50 PM
79,TVCG,TVCG,InfoVis,MARVisT: Authoring Glyph-based Visualization in Mobile Augmented Reality,"Zhutian Chen, Yijia Su, Yifang Wang, Qianwen Wang, Huamin Qu, Yingcai Wu",,,,,,,,vimeo 364568467,,10.1109/TVCG.2019.2892415,?,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,2:20 PM,2:35 PM
80,InfoVis,TVCG,InfoVis,Designing for Mobile and Immersive Visual Analytics in the Field,"Matt Whitlock, Keke Wu, Danielle Albers Szafir",https://arxiv.org/pdf/1908.00680.pdf,"Data collection and analysis in the field is critical for operations in domains such as environmental science and public safety. However, field workers currently face data- and platform-oriented issues in efficient data collection and analysis in the field, such as limited connectivity, screen space, and attentional resources. In this paper, we explore how visual analytics tools might transform field practices by more deeply integrating data into these operations. We use a design probe coupling mobile, cloud, and immersive analytics components to guide interviews with ten experts from five domains to explore how visual analytics could support data collection and analysis needs in the field. The results identify shortcomings of current approaches and target scenarios and design considerations for future field analysis systems. We embody these findings in FieldView, an extensible, open-source prototype designed to support critical use cases for situated field analysis. Our findings suggest the potential for integrating mobile and immersive technologies to enhance data’s utility for various field operations and new directions for visual analytics tools to transform fieldwork.",,,,,https://cmci.colorado.edu/visualab/fieldview/,vimeo 360050322,,10.1109/TVCG.2019.2934282,2019,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,2:35 PM,2:50 PM
81,InfoVis,TVCG,InfoVis,Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration,"Jorge A. Wagner, Wolfgang Stuerzlinger, Luciana Nedel",https://arxiv.org/pdf/1908.00580.pdf,"A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst’s real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.",,,,,,vimeo 360049740,,,2019,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,2:50 PM,3:05 PM
82,InfoVis,TVCG,InfoVis,The Impact of Immersion on Cluster Identification Tasks,"Matthias Kraus, Niklas Kai Weiler, Daniela Oelke, Johannes Kehrer, Daniel Keim, Johannes Fuchs",,,,,,,,vimeo 360049662,,,2019,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,3:05 PM,3:20 PM
83,InfoVis,TVCG,InfoVis,"There Is No Spoon: Evaluating Performance, Space Use, and Presence with Expert Domain Users in Immersive Analytics","Andrea Batch, Andrew Cunningham, Maxime Cordeil, Niklas Elmqvist, Tim Dwyer, Bruce H Thomas, Kim Marriott",https://osf.io/wzqbu,"Immersive analytics turns the very space surrounding the user into a canvas for data analysis, supporting human cognitive abilities in myriad ways. We present the results of a design study, contextual inquiry, and longitudinal evaluation involving professional economists using a Virtual Reality (VR) system for multidimensional visualization to explore actual economic data. Results from our preregistered evaluation highlight the varied use of space depending on context (exploration vs. presentation), the organization of space to support work, and the impact of immersion on navigation and orientation in the 3D analysis space.",,https://osf.io/jhnuc/,,,,vimeo 360050033,,,2019,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,3:20 PM,3:35 PM
84,SciVis,TVCG,SciVis,Deadeye Visualization Revisited: Investigation of Preattentiveness and Applicability in Virtual Environments,"Andrey Krekhov, Sebastian Cmentowski, Andre Waschk, Jens Krueger",https://arxiv.org/pdf/1907.04702.pdf,"Visualizations rely on highlighting to attract and guide our attention. To make an object of interest stand out independently from a number of distractors, the underlying visual cue, e.g., color, has to be preattentive. In our prior work, we introduced Deadeye as an instantly recognizable highlighting technique that works by rendering the target object for one eye only. In contrast to prior approaches, Deadeye excels by not modifying any visual properties of the target. However, in the case of 2D visualizations, the method requires an additional setup to allow dichoptic presentation, which is a considerable drawback. As a follow-up to requests from the community, this paper explores Deadeye as a highlighting technique for 3D visualizations, because such stereoscopic scenarios support dichoptic presentation out of the box. Deadeye suppresses binocular disparities for the target object, so we cannot assume the applicability of our technique as a given fact. With this motivation, the paper presents quantitative evaluations of Deadeye in VR, including configurations with multiple heterogeneous distractors as an important robustness challenge. After confirming the preserved preattentiveness (all average accuracies above 90 %) under such real-world conditions, we explore VR volume rendering as an example application scenario for Deadeye. We depict a possible workflow for integrating our technique, conduct an exploratory survey to demonstrate benefits and limitations, and finally provide related design implications",,,,,,vimeo 359999349,,10.1109/TVCG.2019.2934370,2019,2019,Ballroom B,Wednesday,Immersion and Virtual Environments,23-Oct,3:35 PM,3:50 PM
85,TVCG,TVCG,InfoVis,Eiffel: Evolutionary Flow Map for Influence Graph Visualization,"Yucheng Huang, Lei Shi, Yue Su, Yifan Hu, Hanghang Tong, Chaoli Wang, Tong Yang, Deyun Wang, Shuo Liang",,,,,,,,vimeo 364568698,,10.1109/TVCG.2019.2906900,?,2019,Ballroom A,Friday,Influencers,25-Oct,9:00 AM,9:15 AM
86,VAST,TVCG,VAST,Galex: Exploring the Evolution and Intersection of Disciplines,"Zeyu Li, Changhong Zhang, Shichao Jia, Jiawan Zhang",,,,,,,,vimeo 360154945,,10.1109/TVCG.2019.2934667,2019,2019,Ballroom A,Friday,Influencers,25-Oct,9:15 AM,9:30 AM
87,VAST,TVCG,VAST,"MetricsVis: A Visual Analytics Framework for Evaluating Individual, Team, and Organization Performance","Jieqiong Zhao, Morteza Karimzadeh, Luke Snyder, Cittayong Surakitbanharn, Zhenyu Cheryl Qian, David Ebert",https://arxiv.org/pdf/1907.13601.pdf,"Evaluating employee performance in organizations with varying workloads and tasks is challenging. Specifically, it is important to understand how quantitative measurements of employee achievements relate to supervisor expectations, what the main drivers of good performance are, and how to combine these complex and flexible performance evaluation metrics into an accurate portrayal of organizational performance in order to identify shortcomings and improve overall productivity. To facilitate this process, we summarize common organizational performance analyses into four visual exploration task categories. Additionally, we develop MetricsVis, a visual analytics system composed of multiple coordinated views to support the dynamic evaluation and comparison of individual, team, and organizational performance in public safety organizations. MetricsVis provides four primary visual components to expedite performance evaluation: (1) a priority adjustment view to support direct manipulation on evaluation metrics; (2) a reorderable performance matrix to demonstrate the details of individual employees; (3) a group performance view that highlights aggregate performance and individual contributions for each group; and (4) a projection view illustrating employees with similar specialties to facilitate shift assignments and training. We demonstrate the usability of our framework with two case studies from medium-sized law enforcement agencies and highlight its broader applicability to other domains.",,,,,,vimeo 360156150,,,2019,2019,Ballroom A,Friday,Influencers,25-Oct,9:30 AM,9:45 AM
88,VAST,VAST,VAST,Influence Flowers of Academic Entities,"Minjeong Shin, Alexander Soen, Benjamin T. Readshaw, Stephen Michael Blackburn, Mitchell Whitelaw, Lexing Xie",https://arxiv.org/pdf/1907.12748.pdf,"We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools <em>quantify influence</em>, we aim to expose <em>the flow of influence between entities</em>. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers’ careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher",http://influencemap.ml/,,,,https://github.com/csmetrics/influencemap,vimeo 360155315,,,2019,2019,Ballroom A,Friday,Influencers,25-Oct,9:45 AM,10:00 AM
89,TVCG,TVCG,VAST,WeSeer: Visual Analysis for Better Information Cascade Prediction of WeChat Articles,"Quan Li, Ziming Wu, Lingling Yi, Kristanto Sean N, Huamin Qu, Xiaojuan Ma",https://arxiv.org/pdf/1808.09068.pdf,"Social media, such as Facebook and WeChat, empowers millions of users to create, consume, and disseminate online information on an unprecedented scale. The abundant information on social media intensifies the competition of WeChat Public Official Articles (i.e., posts) for gaining user attention due to the zero-sum nature of attention. Therefore, only a small portion of information tends to become extremely popular while the rest remains unnoticed or quickly disappears. Such a typical “long-tail” phenomenon is very common in social media. Thus, recent years have witnessed a growing interest in predicting the future trend in the popularity of social media posts and understanding the factors that influence the popularity of the posts. Nevertheless, existing predictive models either rely on cumbersome feature engineering or sophisticated parameter tuning, which are difficult to understand and improve. In this paper, we study and enhance a point process-based model by incorporating visual reasoning to support communication between the users and the predictive model for a better prediction result. The proposed system supports users to uncover the working mechanism behind the model and improve the prediction accuracy accordingly based on the insights gained. We use realistic WeChat articles to demonstrate the effectiveness of the system and verify the improved model on a large scale of WeChat articles. We also elicit and summarize the feedback from WeChat domain experts.",,,,,,vimeo 364571456,,10.1109/TVCG.2018.2867776,?,2019,Ballroom A,Friday,Influencers,25-Oct,10:00 AM,10:15 AM
90,VAST,TVCG,VAST,R-Map: A Map Metaphor for Visualizing Information Reposting Process in Social Media,"Shuai Chen, Sihang Li, Siming Chen, Xiaoru Yuan",,,,,,,,vimeo 360155374,,10.1109/TVCG.2019.2934263,2019,2019,Ballroom A,Friday,Influencers,25-Oct,10:15 AM,10:30 AM
91,InfoVis,TVCG,InfoVis,DataShot: Automatic Generation of Fact Sheet from Tabular Data,"Yun Wang, Zhida Sun, Haidong Zhang, Weiwei Cui, Ke Xu, Xiaojuan Ma, Dongmei Zhang",,,,,,,,vimeo 360049797,,,2019,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,2:20 PM,2:35 PM
92,InfoVis,TVCG,InfoVis,Text-to-Viz: Automatic Generation of Infographics from Natural Language Statements,"Weiwei Cui, Xiaoyu Zhang, Yun Wang, He Huang, Bei Chen, Lei Fang, Haidong Zhang, Jian-Guang Lou, Dongmei Zhang",https://arxiv.org/pdf/1907.09091.pdf,"Combining data content with visual embellishments, infographics can effectively deliver messages in an engaging and memorable manner. Various authoring tools have been proposed to facilitate the creation of infographics. However, creating a professional infographic with these authoring tools is still not an easy task, requiring much time and design expertise. Therefore, these tools are generally not attractive to casual users, who are either unwilling to take time to learn the tools or lacking in proper design expertise to create a professional infographic. In this paper, we explore an alternative approach: to automatically generate infographics from natural language statements. We first conducted a preliminary study to explore the design space of infographics. Based on the preliminary study, we built a proof-of-concept system that automatically converts statements about simple proportionrelated statistics to a set of infographics with pre-designed styles. Finally, we demonstrated the usability and usefulness of the system through sample results, exhibits, and expert reviews.",,,,,,,,,2019,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,2:35 PM,2:50 PM
93,InfoVis,TVCG,InfoVis,Towards Automated Infographic Design: Deep Learning-based Auto-Generation of Extensible Timeline,"Zhutian Chen, Yun Wang, Qianwen Wang, Yong Wang, Huamin Qu",https://arxiv.org/pdf/1907.13550.pdf,"Designers need to consider not only perceptual effectiveness but also visual styles when creating an infographic. This process can be difficult and time consuming for professional designers, not to mention non-expert users, leading to the demand for automated infographics design. As a first step, we focus on timeline infographics, which have been widely used for centuries. We contribute an end-to-end approach that automatically extracts an extensible timeline template from a bitmap image. Our approach adopts a deconstruction and reconstruction paradigm. At the deconstruction stage, we propose a multi-task deep neural network that simultaneously parses two kinds of information from a bitmap timeline: 1) the global information, i.e., the representation, scale, layout, and orientation of the timeline, and 2) the local information, i.e., the location, category, and pixels of each visual element on the timeline. At the reconstruction stage, we propose a pipeline with three techniques, i.e., Non-Maximum Merging, Redundancy Recover, and DL GrabCut, to extract an extensible template from the infographic, by utilizing the deconstruction results. To evaluate the effectiveness of our approach, we synthesize a timeline dataset (4296 images) and collect a real-world timeline dataset (393 images) from the Internet. We first report quantitative evaluation results of our approach over the two datasets. Then, we present examples of automatically extracted templates and timelines automatically generated based on these templates to qualitatively demonstrate the performance. The results confirm that our approach can effectively extract extensible templates from real-world timeline infographics.",,,,,,,,,2019,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,2:50 PM,3:05 PM
94,VAST,TVCG,VAST,EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos,"Haipeng Zeng, Xingbo Wang, Aoyu Wu, Yong Wang, Quan Li, Alex Endert, Huamin Qu",https://arxiv.org/pdf/1907.12918.pdf,"Emotions play a key role in human communication and public presentations. Human emotions are usually expressed through multiple modalities. Therefore, exploring multimodal emotions and their coherence is of great value for understanding emotional expressions in presentations and improving presentation skills. However, manually watching and studying presentation videos is often tedious and time-consuming. There is a lack of tool support to help conduct an efficient and in-depth multi-level analysis. Thus, in this paper, we introduce EmoCo, an interactive visual analytics system to facilitate efficient analysis of emotion coherence across facial, text, and audio modalities in presentation videos. Our visualization system features a channel coherence view and a sentence clustering view that together enable users to obtain a quick overview of emotion coherence and its temporal evolution. In addition, a detail view and word view enable detailed exploration and comparison from the sentence level and word level, respectively. We thoroughly evaluate the proposed system and visualization techniques through two usage scenarios based on TED Talk videos and interviews with two domain experts. The results demonstrate the effectiveness of our system in gaining insights into emotion coherence in presentations.",,,,,,vimeo 360154890,,10.1109/TVCG.2019.2934656,2019,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,3:05 PM,3:20 PM
95,TVCG,TVCG,VAST,Multimodal Analysis of Video Collections: Visual Exploration of Presentation Techniques in TED Talks,"Aoyu Wu, Huamin Qu",,,,,,,,vimeo 364568236,,10.1109/TVCG.2018.2889081,?,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,3:20 PM,3:35 PM
96,TVCG,TVCG,VAST,Supporting Story Synthesis: Bridging the Gap between Visual Analytics and Storytelling,"Siming Chen, Jie Li, Gennady Andrienko, Natalia Andrienko, Yun Wang, Phong H. Nguyen, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/21217/1/tvcg19-storySynthesis.pdf,"Visual analytics usually deals with complex data and uses sophisticated algorithmic, visual, and interactive techniques supporting the analysis. Findings and results of the analysis often need to be communicated to an audience that lacks visual analytics expertise. This requires analysis outcomes to be presented in simpler ways than that are typically used in visual analytics systems. However, not only analytical visualizations may be too complex for target audiences but also the information that needs to be presented. Analysis results may consist of multiple components, which may involve multiple heterogeneous facets. Hence, there exists a gap on the path from obtaining analysis findings to communicating them, within which two main challenges lie: information complexity and display complexity. We address this problem by proposing a general framework where data analysis and result presentation are linked by story synthesis, in which the analyst creates and organises story contents. Unlike previous research, where analytic findings are represented by stored display states, we treat findings as data constructs. We focus on selecting, assembling and organizing findings for further presentation rather than on tracking analysis history and enabling dual (i.e., explorative and communicative) use of data displays. In story synthesis, findings are selected, assembled, and arranged in meaningful layouts that take into account the structure of information and inherent properties of its components. We propose a workflow for applying the proposed conceptual framework in designing visual analytics systems and demonstrate the generality of the approach by applying it to two diverse domains, social media and movement analysis.",,,,,,vimeo 364568266,,10.1109/TVCG.2018.2889054,?,2019,Ballroom C,Thursday,Infographics & Storytelling,24-Oct,3:35 PM,3:50 PM
97,InfoVis,TVCG,InfoVis,Illusion of Causality in Visualized Data,"Cindy Xiong, Joel Shapiro, Jessica Hullman, Steven Franconeri",https://arxiv.org/pdf/1908.00215.pdf,"Students who eat breakfast more frequently tend to have a higher grade point average. From this data, many people might confidently state that a before-school breakfast program would lead to higher grades. This is a reasoning error, because correlation does not necessarily indicate causation – X and Y can be correlated without one directly causing the other. While this error is pervasive, its prevalence might be amplified or mitigated by the way that the data is presented to a viewer. Across three crowdsourced experiments, we examined whether how simple data relations are presented would mitigate this reasoning error. The first experiment tested examples similar to the breakfast-GPA relation, varying in the plausibility of the causal link. We asked participants to rate their level of agreement that the relation was correlated, which they rated appropriately as high. However, participants also expressed high agreement with a causal interpretation of the data. Levels of support for the causal interpretation were not equally strong across visualization types: causality ratings were highest for text descriptions and bar graphs, but weaker for scatter plots. But is this effect driven by bar graphs aggregating data into two groups or by the visual encoding type? We isolated data aggregation versus visual encoding type and examined their individual effect on perceived causality. Overall, different visualization designs afford different cognitive reasoning affordances across the same data. High levels of data aggregation by graphs tend to be associated with higher perceived causality in data. Participants perceived line and dot visual encodings as more causal than bar encodings. Our results demonstrate how some visualization designs trigger stronger causal links while choosing others can help mitigate unwarranted perceptions of causality.",,,,,,vimeo 360049821,,10.1109/TVCG.2019.2934399,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,2:20 PM,2:35 PM
98,VAST,TVCG,VAST,"Ablate, Variate, and Contemplate:Visual Analytics for Discovering Neural Architectures","Dylan Cashman, Adam Perer, Remco Chang, Hendrik Strobelt",https://arxiv.org/pdf/1908.00387.pdf,"Deep learning models require the configuration of many layers and parameters in order to get good results. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.",http://www.eecs.tufts.edu/~dcashm01/snacs/,,,,https://github.com/dylancashman/remap_nas.,,,,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,2:35 PM,2:50 PM
99,VAST,TVCG,VAST,VASSL: A Visual Analytics Toolkit for Social Spambot Labeling,"Mosab Khayat, Morteza Karimzadeh, Jieqiong Zhao, David Ebert",https://arxiv.org/pdf/1907.13319.pdf,"Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.",,,,,,vimeo 360155523,,10.1109/TVCG.2019.2934266,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,2:50 PM,3:05 PM
100,VAST,TVCG,VAST,Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,"Sebastian Gehrmann, Hendrik Strobelt, Robert Krüger, Kathryn Hite, Hanspeter Pfister, Alexander M. Rush",https://arxiv.org/pdf/1907.10739.pdf,"Automation of tasks can have critical consequences when humans lose agency over decision processes. Deep learning models are particularly susceptible since current black-box approaches lack explainable reasoning. We argue that both the visual interface and model structure of deep learning systems need to take into account interaction design. We propose a framework of collaborative semantic inference (CSI) for the co-design of interactions and models to enable visual collaboration between humans and algorithms. The approach exposes the intermediate reasoning process of models which allows semantic interactions with the visual metaphors of a problem, which means that a user can both understand and control parts of the model reasoning process. We demonstrate the feasibility of CSI with a co-designed case study of a document summarization system.",,,,,,vimeo 360155863,,10.1109/TVCG.2019.2934595,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,3:05 PM,3:20 PM
101,VAST,VAST,VAST,ICE: An Interactive Configuration Explorer for High Dimensional Parameter Spaces,"Anjul Tyagi, Klaus Mueller, Zhen Cao, Tyler Estro, Erez Zadok",https://arxiv.org/pdf/1907.12627.pdf,"There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables. However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system
was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with
expert interviews, a comparative user study, and two case studies.",,,,,,vimeo 360156102,,,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,3:20 PM,3:35 PM
102,VAST,VAST,VAST,Interactive Correction of Mislabeled Training Data,"Xi Ye, Shouxing Xiang, Jiazhi Xia, Jing Wu, Yang Chen, Shixia Lu",,,,,,,,vimeo 360154277,,,2019,2019,Ballroom B,Thursday,Interactive Machine Learning,24-Oct,3:35 PM,3:50 PM
103,InfoVis,TVCG,InfoVis,OntoPlot: A Novel Visualisation for Non-hierarchical Associations in Large Ontologies,"Ying Yang, Michael Wybrow, Yuan-Fang Li, Tobias Czauderna, Yongqun He",https://monash.figshare.com/articles/OntoPlot_A_Novel_Visualisation_for_Non-hierarchical_Associations_in_Large_Ontologies/9204449/2,"Biologists often use computer graphics to visualize structures, which due to physical limitations are not possible to image with a microscope. One example for such structures are microtubules, which are present in every eukaryotic cell. They are part of the cytoskeleton maintaining the shape of the cell and playing a key role in the cell division. In this paper, we propose a scientificallyaccurate multi-scale procedural model of microtubule dynamics as a novel application scenario for procedural animation, which can generate visualizations of their overall shape, molecular structure, as well as animations of the dynamic behaviour of their growth and disassembly. The model is spanning from tens of micrometers down to atomic resolution. All the aspects of the model are driven by scientific data. The advantage over a traditional, manual animation approach is that when the underlying data change, for instance due to new evidence, the model can be recreated immediately. The procedural animation concept is presented in its generic form, with several novel extensions, facilitating an easy translation to other domains with emergent multi-scale behavior.",,,,,,vimeo 360050594,,10.1109/TVCG.2019.2934557,2019,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,9:00 AM,9:15 AM
104,InfoVis,TVCG,InfoVis,P5: Portable Progressive Parallel Processing Pipeline for Interactive Data Analysis and Visualization,"Kelvin Li, Kwan-Liu Ma",,,,,,,,vimeo 360050527,,,2019,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,9:15 AM,9:30 AM
105,InfoVis,TVCG,InfoVis,RSATree: Distribution-Aware Data Representation of Large-Scale Tabular Datasets for Flexible Visual Query,"Honghui Mei, Yating Wei, Shuyue Zhou, Bingru Lin, Yuanzhe Hu, Ying Zhao, Jiazhi Xia, Wei Chen",https://arxiv.org/pdf/1908.02005.pdf,"Analysts commonly investigate the data distributions derived from statistical aggregations of data that are represented by charts, such as histograms and binned scatterplots, to visualize and analyze a large-scale dataset. Aggregate queries are implicitly executed through such a process. Datasets are constantly extremely large; thus, the response time should be accelerated by calculating predefined data cubes. However, the queries are limited to the predefined binning schema of preprocessed data cubes. Such limitation hinders analysts flexible adjustment of visual specifications to investigate the implicit patterns in the data effectively. Particularly, RSATree enables arbitrary queries and flexible binning strategies by leveraging three schemes, namely, an R-tree-based space partitioning scheme to catch the data distribution, a locality-sensitive hashing technique to achieve locality-preserving random access to data items, and a summed area table scheme to support interactive query of aggregated values with a linear computational complexity. This study presents and implements a web-based visual query system that supports visual specification, query, and exploration of large-scale tabular data with user-adjustable granularities. We demonstrate the efficiency and utility of our approach by performing various experiments on real-world datasets and analyzing time and space complexity.",,,,,,vimeo 360049964,,,2019,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,9:30 AM,9:45 AM
106,TVCG,TVCG,InfoVis,SolarView: Low Distortion Radial Embedding with a Focus,"Thom Castermans, Kevin Verbeek, Bettina Speckmann, Michel A. Westenberg, Rob Koopman, Shenghui Wang, Hein van den Berg, Arianna Betti",,,,,,,,vimeo 364568393,,,?,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,9:45 AM,10:00 AM
107,TVCG,TVCG,SciVis,Scientific Visualization as a Microservice,"Mohammad Raji, Alok Hota, Tanner Hobson, Jian Huang",,,,,,,,vimeo 364569370,,10.1109/TVCG.2018.2879672,?,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,10:00 AM,10:15 AM
108,VAST,TVCG,VAST,GPGPU Linear Complexity tSNE Optimization,"Nicola Pezzotti, Julian Thijssen, Alexander Mordvintsev, Thomas Höllt, Baldur van Lew, Boudewijn P.F. Lelieveldt, Elmar Eisemann, Anna Vilanova",,,,,,,,vimeo 360155729,,,2019,2019,Ballroom C,Thursday,Large Data and Dimensionality Reduction,24-Oct,10:15 AM,10:30 AM
109,InfoVis,TVCG,InfoVis,Pattern-Driven Navigation in 2D Multiscale Visualizations with Scalable Insets,"Fritz Lekschas, Michael Behrisch, Benjamin Bach, Peter Kerpedjiev, Nils Gehlenborg, Hanspeter Pfister",https://www.biorxiv.org/content/biorxiv/early/2019/04/04/301036.full.pdf,"We present Scalable Insets, a technique for interactively exploring and navigating large numbers of annotated patterns in multiscale visual spaces such as gigapixel images, matrices, or maps. Exploration of many but sparselydistributed patterns in multiscale visual spaces is challenging as visual representations change across zoom levels, context and navigational cues get lost upon zooming, and navigation is time consuming. Our technique visualizes annotated patterns too small to be identifiable at certain zoom levels using insets, i.e., magnified thumbnail views of the annotated pattern. Insets support users in searching, comparing, and contextualizing patterns, while reducing the amount of navigation needed. They are dynamically placed either within the viewport or along the boundary of the viewport to offer a compromise between locality and context preservation. Annotated patterns are interactively clustered by location and type. They are visually represented as an aggregated inset to provide scalable exploration within a single viewport. A controlled user study with 18 participants found improved performance in visual search (up to 45% faster) and comparison of pattern types (up to 32 percentage points more accurate) compared to a baseline technique. A second study with 6 experts in the field of genomics showed that Scalable Insets are easy to learn and effective in a biological data exploration scenario",,,https://github.com/flekschas/higlass-scalable-insets,,https://github.com/flekschas/higlass-scalable-insets,vimeo 360445699,,,2019,2019,Ballroom A,Wednesday,Multiscale Visualization,23-Oct,9:00 AM,9:15 AM
110,SciVis,TVCG,SciVis,Multi-Scale Procedural Animations of Microtubule Dynamics Based on Measured Data,"Tobias Klein, Ivan Viola, Eduard Gröller, Peter Mindek",,,,,,,,vimeo 359999585,vimeo 368590395,,2019,2019,Ballroom A,Wednesday,Multiscale Visualization,23-Oct,9:15 AM,9:30 AM
111,SciVis,TVCG,SciVis,OpenSpace: A System for Astrographics,"Alexander Bock, Emil Axelsson, Jonathas Costa, Gene Payne, Micah Acinapura, Vivian Trakinski, Carter B Emmart PhD, Claudio Silva, Charles Hansen, Anders Ynnerman",,,,,,,,vimeo 359998824,vimeo 368590395,10.1109/TVCG.2019.2934259,2019,2019,Ballroom A,Wednesday,Multiscale Visualization,23-Oct,9:30 AM,9:45 AM
112,SciVis,TVCG,SciVis,Scale-Space Splatting: Reforming Spacetime for the Cross-Scale Exploration of Integral Measures in Molecular Dynamics,"Juraj Pálenik, Jan Byška, Stefan Bruckner, Helwig Hauser",https://arxiv.org/pdf/1907.09939.pdf,"Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein–ligand simulation.",,,,,,vimeo 359998771,,,2019,2019,Ballroom A,Wednesday,Multiscale Visualization,23-Oct,9:45 AM,10:00 AM
113,SciVis,TVCG,SciVis,ScaleTrotter: Illustrative Visual Travels Across Negative Scales,"Sarkis Halladjian, Haichao Miao, David Kouřil, Eduard Gröller, Ivan Viola, Tobias Isenberg",https://arxiv.org/pdf/1907.12352.pdf,"We present ScaleTrotter, a conceptual framework for an interactive, multi-scale visualization of biological mesoscale data and, specifically, genome data. ScaleTrotter allows viewers to smoothly transition from the nucleus of a cell to the atomistic composition of the DNA, while bridging several orders of magnitude in scale. The challenges in creating an interactive visualization of genome data are fundamentally different in several ways from those in other domains like astronomy that require a multi-scale representation as well. First, genome data has intertwined scale levels—the DNA is an extremely long, connected molecule that manifests itself at all scale levels. Second, elements of the DNA do not disappear as one zooms out—instead the scale levels at which they are observed group these elements differently. Third, we have detailed information and thus geometry for the entire dataset and for all scale levels, posing a challenge for interactive visual exploration. Finally, the conceptual scale levels for genome data are close in scale space, requiring us to find ways to visually embed a smaller scale into a coarser one. We address these challenges by creating a new multi-scale visualization concept. We use a scale-dependent camera model that controls the visual embedding of the scales into their respective parents, the rendering of a subset of the scale hierarchy, and the location, size, and scope of the view. In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual representations that are depicted in integrated visuals. We discuss, specifically, how this form of multi-scale visualization follows from the specific characteristics of the genome data and describe its implementation. Finally, we discuss the implications of our work to the general illustrative depiction of multi-scale data.",,,,,,vimeo 359999391,vimeo 368618319,10.1109/TVCG.2019.2934334,2019,2019,Ballroom A,Wednesday,Multiscale Visualization,23-Oct,10:00 AM,10:15 AM
114,TVCG,TVCG,VAST,Taxonomizer: A Visual Analytics Framework for Constructing Fully Labeled Hierarchies from Multivariate Data,"Salman Mahmood, Klaus Mueller",,,,,,,,vimeo 364568009,,,?,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,10:50 AM,11:05 AM
115,InfoVis,TVCG,InfoVis,An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data,"Takanori Fujiwara, Jia-Kai Chou, Shilpika Shilpika, Panpan Xu, Liu Ren, Kwan-Liu Ma",https://arxiv.org/pdf/1905.04000.pdf,"Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer’s mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.",,,,,,vimeo 360050443,,,2019,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,11:05 AM,11:20 AM
116,TVCG,TVCG,SciVis,Generalizing Iso-surfaces to Multi-variate Data,"Jochen Jankowai, Ingrid Hotz",,,,,,,,vimeo 364568992,,,?,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,11:20 AM,11:35 AM
117,TVCG,TVCG,SciVis,TTHRESH: Tensor Compression for Multidimensional Visual Data,"Rafael Ballester-Ripoll, Peter Lindstrom, Renato Pajarola",https://arxiv.org/pdf/1806.05952.pdf,"Memory and network bandwidth are decisive bottlenecks when handling high-resolution multidimensional data sets in visualization applications, and they increasingly demand suitable data compression strategies. We introduce a novel lossy compression algorithm for multidimensional data over regular grids. It leverages the higher-order singular value decomposition (HOSVD), a generalization of the SVD to three dimensions and higher, together with bit-plane, run-length and arithmetic coding to compress the HOSVD transform coefficients. Our scheme degrades the data particularly smoothly and achieves lower mean squared error than other state-of-the-art algorithms at low-to-medium bit rates, as it is required in data archiving and management for visualization purposes. Further advantages of the proposed algorithm include very fine bit rate selection granularity and the ability to manipulate data at very small cost in the compression domain, for example to reconstruct filtered and/or subsampled versions of all (or selected parts) of the data set.",,,,,,vimeo 364569449,,10.1109/TVCG.2019.2904063,?,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,11:35 AM,11:50 AM
118,VAST,TVCG,VAST,Selection Bias Tracking and Detailed Subset Comparison for High-Dimensional Data,"David Borland, Wenyuan Wang, Jonathan Zhang, Joshua Shrestha, David Gotz",https://arxiv.org/pdf/1906.07625.pdf,"The collection of large, complex datasets has become common across a wide variety of domains. Visual analytics tools increasingly play a key role in exploring and answering complex questions about these large datasets. However, many visualizations are not designed to concurrently visualize the large number of dimensions present in complex datasets (e.g. tens of thousands of distinct codes in an electronic health record system). This fact, combined with the ability of many visual analytics systems to enable rapid, ad-hoc specification of groups, or cohorts, of individuals based on a small subset of visualized dimensions, leads to the possibility of introducing selection bias–when the user creates a cohort based on a specified set of dimensions, differences across many other unseen dimensions may also be introduced. These unintended side effects may result in the cohort no longer being representative of the larger population intended to be studied, which can negatively affect the validity of subsequent analyses. We present techniques for selection bias tracking and visualization that can be incorporated into high-dimensional exploratory visual analytics systems, with a focus on medical data with existing data hierarchies. These techniques include: (1) tree-based cohort provenance and visualization, including a user-specified baseline cohort that all other cohorts are compared against, and visual encoding of cohort “drift”, which indicates where selection bias may have occurred, and (2) a set of visualizations, including a novel icicle-plot based visualization, to compare in detail the per-dimension differences between the baseline and a user-specified focus cohort. These techniques are integrated into a medical temporal event sequence visual analytics tool. We present example use cases and report findings from domain expert user interviews.",,,,,,vimeo 360154972,,10.1109/TVCG.2019.2934209,2019,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,11:50 AM,12:05 PM
119,VAST,TVCG,VAST,Visual Analysis of High-Dimensional Event Sequence Data via Dynamic Hierarchical Aggregation,"David Gotz, Jonathan Zhang, Wenyuan Wang, Joshua Shrestha, David Borland",https://arxiv.org/pdf/1906.07617.pdf,"Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places significant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predefined hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a specific analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report findings from domain expert interviews.",,,,,,vimeo 360154915,,10.1109/TVCG.2019.2934661,2019,2019,Ballroom C,Wednesday,Multivariate & Multidimensional Data,23-Oct,12:05 PM,12:20 PM
120,VAST,TVCG,VAST,Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness,"Luke Snyder, Yi-Shan Lin, Morteza Karimzadeh, Dan Goldwasser, David Ebert",https://arxiv.org/pdf/1908.02588.pdf,"Various domain users are increasingly leveraging real-time social media data to gain rapid situational awareness. However, due to the high noise in the deluge of data, effectively determining semantically relevant information can be difficult, further complicated by the changing definition of relevancy by each end user for different events. The majority of existing methods for short text relevance classification fail to incorporate users’ knowledge into the classification process. Existing methods that incorporate interactive user feedback focus on historical datasets. Therefore, classifiers cannot be interactively retrained for specific events or user-dependent needs in real-time. This limits real-time situational awareness, as streaming data that is incorrectly classified cannot be corrected immediately, permitting the possibility for important incoming data to be incorrectly classified as well. We present a novel interactive learning framework to improve the classification process in which the user iteratively corrects the relevancy of tweets in real-time to train the classification model on-the-fly for immediate predictive improvements. We computationally evaluate our classification model adapted to learn at interactive rates. Our results show that our approach outperforms state-of-the-art machine learning models. In addition, we integrate our framework with the extended Social Media Analytics and Reporting Toolkit (SMART) 2.0 system, allowing the use of our interactive learning framework within a visual analytics system tailored for real-time situational awareness. To demonstrate our framework’s effectiveness, we provide domain expert feedback from first responders who used the extended SMART 2.0 system.",,,,,,vimeo 360154855,,10.1109/TVCG.2019.2934614,2019,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,2:20 PM,2:35 PM
121,TVCG,TVCG,InfoVis,A Systematic Review of Visualization in Building Information Modeling,"Paulo Ivson, André Moreira, Francisco Queiroz, Wallas Santos, Waldemar Celes",http://eprints.whiterose.ac.uk/146384/1/author_TVCG2907583.pdf,"Building Information Modeling (BIM) employs data-rich 3D CAD models for large-scale facility design, construction, and operation. These complex datasets contain a large amount and variety of information, ranging from design specifications to real-time sensor data. They are used by architects and engineers for various analysis and simulations throughout a facility’s life cycle. Many techniques from different visualization fields could be used to analyze these data. However, the BIM domain still remains largely unexplored by the visualization community. The goal of this article is to encourage visualization researchers to increase their involvement with BIM. To this end, we present the results of a systematic review of visualization in current BIM practice. We use a novel taxonomy to identify main application areas and analyze commonly employed techniques. From this domain characterization, we highlight future research opportunities brought forth by the unique features of BIM. For instance, exploring the synergies between scientific and information visualization to integrate spatial and non-spatial data. We hope this article raises awareness to interesting new challenges the BIM domain brings to the visualization community.",,,,,,vimeo 364569766,,10.1109/TVCG.2019.2907583,?,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,2:35 PM,2:50 PM
122,VAST,TVCG,VAST,"LightGuider: Guiding Interactive Lighting Design using Suggestions, Provenance, and Quality Visualization","Andreas Walch, Michael Schwärzler, Christian Luksch, Elmar Eisemann, Theresia Gschwandtner",,,,,,,,vimeo 360154391,,10.1109/TVCG.2019.2934658,2019,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,2:50 PM,3:05 PM
123,VAST,TVCG,VAST,PlanningVis: A Visual Analytics Approach to Production Planning in Smart Factories,"Dong Sun, Renfei Huang, Yong Wang, Yuanzhe Chen, Jia Zeng, Mingxuan Yuan, Ting-Cheun Pong, Huamin Qu",https://arxiv.org/pdf/1907.12201.pdf,"Production planning in the manufacturing industry is crucial for fully utilizing factory resources (e.g., machines, raw materials and workers) and reducing costs. With the advent of industry 4.0, plenty of data recording the status of factory resources have been collected and further involved in production planning, which brings an unprecedented opportunity to understand, evaluate and adjust complex production plans through a data-driven approach. However, developing a systematic analytics approach for production planning is challenging due to the large volume of production data, the complex dependency between products, and unexpected changes in the market and the plant. Previous studies only provide summarized results and fail to show details for comparative analysis of production plans. Besides, the rapid adjustment to the plan in the case of an unanticipated incident is also not supported. In this paper, we propose PlanningVis, a visual analytics system to support the exploration and comparison of production plans with three levels of details: a plan overview presenting the overall difference between plans, a product view visualizing various properties of individual products, and a production detail view displaying the product dependency and the daily production details in related factories. By integrating an automatic planning algorithm with interactive visual explorations, PlanningVis can facilitate the efficient optimization of daily production planning as well as support a quick response to unanticipated incidents in manufacturing. Two case studies with real-world data and carefully designed interviews with domain experts demonstrate the effectiveness and usability of PlanningVis.",,,,,,vimeo 360155601,,10.1109/TVCG.2019.2934275,2019,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,3:05 PM,3:20 PM
124,VAST,TVCG,VAST,Visual Analytics for Electromagnetic Situation Awareness in Radio Monitoring and Management,"Ying Zhao, Xiaobo Luo, Xiaru Lin, Hairong Wang, Xiaoyan Kui, Fangfang Zhou, Jinsong Wang, Yi Chen, Wei Chen",,,,,,,,vimeo 360154252,,,2019,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,3:20 PM,3:35 PM
125,VAST,TVCG,VAST,sPortfolio: Stratified Visual Analysis of Stock Portfolios,"Xuanwu Yue, Jiaxin Bai, Qinhan Liu, Yiyang Tang, Abishek Puri, Ke Li, Huamin Qu",https://arxiv.org/pdf/1910.05536.pdf,"Quantitative Investment, built on the solid foundation of robust financial theories, is at the center stage in investment industry today. The essence of quantitative investment is the multi-factor model, which explains the relationship between the risk and return of equities. However, the multi-factor model generates enormous quantities of factor data, through which even experienced portfolio managers find it difficult to navigate. This has led to portfolio analysis and factor research being limited by a lack of intuitive visual analytics tools. Previous portfolio visualization systems have mainly focused on the relationship between the portfolio return and stock holdings, which is insufficient for making actionable insights or understanding market trends. In this paper, we present sPortfolio, which, to the best of our knowledge, is the first visualization that attempts to explore the factor investment area. In particular, sPortfolio provides a holistic overview of the factor data and aims to facilitate the analysis at three different levels: a Risk-Factor level, for a general market situation analysis; a Multiple-Portfolio level, for understanding the portfolio strategies; and a Single-Portfolio level, for investigating detailed operations. The system’s effectiveness and usability are demonstrated through three case studies. The system has passed its pilot study and is soon to be deployed in industry.",,,,,,vimeo 360154484,,,2019,2019,Ballroom C,Wednesday,Planning and Situational Awareness,23-Oct,3:35 PM,3:50 PM
126,TVCG,TVCG,VAST,ScatterNet: A Deep Subjective Similarity Model for Visual Analysis of Scatterplots,"Yuxin Ma, Anthony K. H. Tung, Wei Wang, Xiang Gao, Zhigeng Pan, Wei Chen",,,,,,,,vimeo 364568078,,10.1109/TVCG.2018.2875702,?,2019,Ballroom A,Thursday,Scatterplots,24-Oct,10:50 AM,11:05 AM
127,InfoVis,TVCG,InfoVis,A Recursive Subdivision Technique for Sampling Multi-class Scatterplots,"Yunhai Wang, Xin Chen, Tong Ge, Jian Zhang, Ying Zhao, Chi-Wing Fu, Baoquan Chen, Oliver Deussen",,,,,,,,vimeo 360050562,,,2019,2019,Ballroom A,Thursday,Scatterplots,24-Oct,11:05 AM,11:20 AM
128,InfoVis,TVCG,InfoVis,Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization,"Ruizhen Hu, Tingkai Sha, Oliver van Kaick, Oliver Deussen, Hui Huang",,,,,,,,vimeo 360049945,,10.1109/TVCG.2019.2934799,2019,2019,Ballroom A,Thursday,Scatterplots,24-Oct,11:20 AM,11:35 AM
129,InfoVis,TVCG,InfoVis,Discriminability Tests for Visualization Effectiveness and Scalability,"Rafael Veras, Christopher Collins",https://arxiv.org/pdf/1907.11358.pdf,"The scalability of a particular visualization approach is limited by the ability for people to discern differences between plots made with different datasets. Ideally, when the data changes, the visualization changes in perceptible ways. This relation breaks down when there is a mismatch between the encoding and the character of the dataset being viewed. Unfortunately, visualizations are often designed and evaluated without fully exploring how they will respond to a wide variety of datasets. We explore the use of an image similarity measure, the Multi-Scale Structural Similarity Index (MS-SSIM), for testing the discriminability of a data visualization across a variety of datasets. MS-SSIM is able to capture the similarity of two visualizations across multiple scales, including low level granular changes and high level patterns. Significant data changes that are not captured by the MS-SSIM indicate visualizations of low discriminability and effectiveness. The measure’s utility is demonstrated with two empirical studies. In the first, we compare human similarity judgments and MS-SSIM scores for a collection of scatterplots. In the second, we compute the discriminability values for a set of basic visualizations and compare them with empirical measurements of effectiveness. In both cases, the analyses show that the computational measure is able to approximate empirical results. Our approach can be used to rank competing encodings on their discriminability and to aid in selecting visualizations for a particular type of data distribution.",,,,,,vimeo 360484488,,,2019,2019,Ballroom A,Thursday,Scatterplots,24-Oct,11:35 AM,11:50 AM
130,InfoVis,TVCG,InfoVis,Improving the Robustness of Scagnostics,"Yunhai Wang, Zeyu Wang, Michael Correll, Zhanglin Cheng, Tingting Liu, Oliver Deussen, Michael Sedlmair",,,,,,,,vimeo 360050165,,10.1109/TVCG.2019.2934796,2019,2019,Ballroom A,Thursday,Scatterplots,24-Oct,11:50 AM,12:05 PM
131,InfoVis,TVCG,InfoVis,Winglets: Visualizing Association with Uncertainty in Multi-class Scatterplots,"Min Lu, Shuaiqi Wang, Joel Lanir, Noa Fish, Yang Yue, Daniel CohenOr, Hui Huang",,,,,,,,vimeo 360050129,,,2019,2019,Ballroom A,Thursday,Scatterplots,24-Oct,12:05 PM,12:20 PM
132,InfoVis,TVCG,InfoVis,Searching the Visual Style and Structure of D3 Visualizations,"Enamul Hoque, Maneesh Agrawala",,,,,,,,vimeo 360050425,,,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,9:00 AM,9:15 AM
133,InfoVis,TVCG,InfoVis,The Role of Latency in Predicting Visual Search Behavior,"Leilani Battle, R. Jordan Crouser, Audace Nakeshimana, Ananda Montoly, Remco Chang, Michael Stonebraker",,,,,,,,vimeo 360050582,,,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,9:15 AM,9:30 AM
134,VAST,TVCG,VAST,A Natural-language-based Visual Query Approach of Uncertain Human Trajectories,"Zhaosong Huang, Ye Zhao, Wei Chen, Shengjie Gao, Kejie Yu, Weixia Xu, Mingjie Tang, Minfeng Zhu, Mingliang Xu",https://arxiv.org/pdf/1908.00277.pdf,"Visual querying is essential for interactively exploring massive trajectory data. However, the data uncertainty imposes profound challenges to fulfill advanced analytics requirements. On the one hand, many underlying data does not contain accurate geographic coordinates, e.g., positions of a mobile phone only refer to the regions (i.e., mobile cell stations) in which it resides, instead of accurate GPS coordinates. On the other hand, domain experts and general users prefer a natural way, such as using a natural language sentence, to access and analyze massive movement data. In this paper, we propose a visual analytics approach that can extract spatial-temporal constraints from a textual sentence and support an effective query method over uncertain mobile trajectory data. It is built up on encoding massive, spatially uncertain trajectories by the semantic information of the POIs and regions covered by them, and then storing the trajectory documents in text database with an effective indexing scheme. The visual interface facilitates query condition specification, situation-aware visualization, and semantic exploration of large trajectory data. Usage scenarios on real-world human mobility datasets demonstrate the effectiveness of our approach.",,,,,,vimeo 360154619,,10.1109/TVCG.2019.2934671,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,9:30 AM,9:45 AM
135,VAST,TVCG,VAST,You can’t always sketch what you want: Understanding Sensemaking in Visual Query Systems,"Doris Jung-Lin Lee, John Lee, Tarique Siddiqui, Jaewoo Kim, Aditya Parameswaran, Karrie Karahalios",https://arxiv.org/pdf/1710.00763.pdf,"Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains—astronomy, genetics, and material science—via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.",,,,,https://github.com/zenvisage/zenvisage,vimeo 360154505,,,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,9:45 AM,10:00 AM
136,VAST,VAST,VAST,"Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation","Melanie Tory, Vidya Setlur",,,,,,,,vimeo 360155144,,,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,10:00 AM,10:15 AM
137,VAST,VAST,VAST,TopicSifter: Interactive Search Space Reduction Through Targeted Topic Modeling,"Hannah Kim, Dongjin Choi, Barry Drake, Alex Endert, Haesun Park",https://arxiv.org/pdf/1907.12079.pdf,"Topic modeling is commonly used to analyze and understand large document collections. However, in practice, users want to focus on specific aspects or “targets” rather than the entire corpus. For example, given a large collection of documents, users may want only a smaller subset which more closely aligns with their interests, tasks, and domains. In particular, our paper focuses on large-scale document retrieval with high recall where any missed relevant documents can be critical. A simple keyword matching search is generally not effective nor efficient as 1) it is difficult to find a list of keyword queries that can cover the documents of interest before exploring the dataset, 2) some documents may not contain the exact keywords of interest but may still be highly relevant, and 3) some words have multiple meanings, which would result in irrelevant documents included in the retrieved subset. In this paper, we present TopicSifter, a visual analytics system for interactive search space reduction. Our system utilizes targeted topic modeling based on nonnegative matrix factorization and allows users to give relevance feedback in order to refine their target and guide the topic modeling to the most relevant results.",,,,,,vimeo 360154312,,,2019,2019,Ballroom C,Friday,Searching & Querying,25-Oct,10:15 AM,10:30 AM
138,VAST,TVCG,VAST,CloudDet: Interactive Visual Analysis of Anomalous Performances in Cloud Computing SystemsD,"Ke Xu, Yun Wang, Leni Yang, Yifang Wang, Bo Qiao, Si Qin, Yong Xu, Haidong Zhang, Huamin Qu",https://arxiv.org/pdf/1907.13187.pdf,"Detecting and analyzing potential anomalous performances in cloud computing systems is essential for avoiding losses to customers and ensuring the efficient operation of the systems. To this end, a variety of automated techniques have been developed to identify anomalies in cloud computing performance. These techniques are usually adopted to track the performance metrics of the system (e.g., CPU, memory, and disk I/O), represented by a multivariate time series. However, given the complex characteristics of cloud computing data, the effectiveness of these automated methods is affected. Thus, substantial human judgment on the automated analysis results is required for anomaly interpretation. In this paper, we present a unified visual analytics system named CloudDet to interactively detect, inspect, and diagnose anomalies in cloud computing systems. A novel unsupervised anomaly detection algorithm is developed to identify anomalies based on the specific temporal patterns of the given metrics data (e.g., the periodic pattern), the results of which are visualized in our system to indicate the occurrences of anomalies. Rich visualization and interaction designs are used to help understand the anomalies in the spatial and temporal context. We demonstrate the effectiveness of CloudDet through a quantitative evaluation, two case studies with real-world data, and interviews with domain experts.",,,,,,vimeo 360154740,,,2019,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,9:00 AM,9:15 AM
139,InfoVis,TVCG,InfoVis,Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns,"Kathryn P Williams, Alex Bigelow, Katherine Isaacs",https://arxiv.org/pdf/1905.13135.pdf,"Common pitfalls in visualization projects include lack of data availability and the domain users’ needs and focus changing too rapidly for the design process to complete. While it is often prudent to avoid such projects, we argue it can be beneficial to engage them in some cases as the visualization process can help refine data collection, solving a “chicken and egg” problem of having the data and tools to analyze it. We found this to be the case in the domain of task parallel computing where such data and tooling is an open area of research. Despite these hurdles, we conducted a design study. Through a tightly-coupled iterative design process, we built Atria, a multi-view execution graph visualization to support performance analysis. Atria simplifies the initial representation of the execution graph by aggregating nodes as related to their line of code. We deployed Atria on multiple platforms, some requiring design alteration. We describe how we adapted the design study methodology to the “moving target” of both the data and the domain experts’ concerns and how this movement kept both the visualization and programming project healthy. We reflect on our process and discuss what factors allow the project to be successful in the presence of changing data and user needs.",,,,,,vimeo 360050356,,10.1109/TVCG.2019.2934285,2019,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,9:15 AM,9:30 AM
140,TVCG,TVCG,InfoVis,How People Visually Represent Discrete Constraint Problem,"Xu Zhu, Miguel A. Nacenta, Özgür Akgun, Peter Nightingale",,,,,,,,vimeo 365291194,,,?,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,9:30 AM,9:45 AM
141,TVCG,TVCG,InfoVis,Preserving Command Line Workflow for a Package Management,"Katherine E. Isaacs, Todd Gamblin",,,,,,,,,,,?,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,9:45 AM,10:00 AM
142,TVCG,TVCG,SciVis,Inviwo - A Visualization System with Usage Abstraction Levels,"Daniel Jönsson, Peter Steneteg, Erik Sundén, Rickard Englund, Sathish Kottravel, Martin Falk, Ingrid Hotz, Anders Ynnerman, Timo Ropinski",https://arxiv.org/pdf/1811.12517.pdf,"The complexity of today’s visualization applications demands specific visualization systems tailored for the development of these applications. Frequently, such systems utilize levels of abstraction to improve the application development process, for instance by providing a data flow network editor. Unfortunately, these abstractions result in several issues, which need to be circumvented through an abstraction-centered system design. Often, a high level of abstraction hides low level details, which makes it difficult to directly access the underlying computing platform, which would be important to achieve an optimal performance. Therefore, we propose a layer structure developed for modern and sustainable visualization systems allowing developers to interact with all contained abstraction levels. We refer to this interaction capabilities as usage abstraction levels, since we target application developers with various levels of experience. We formulate the requirements for such a system, derive the desired architecture, and present how the concepts have been exemplary realized within the Inviwo visualization system. Furthermore, we address several specific challenges that arise during the realization of such a layered architecture, such as communication between different computing platforms, performance centered encapsulation, as well as layer-independent development by supporting cross layer documentation and debugging capabilities.",,,,,,,,10.1109/TVCG.2019.2920639,?,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,10:00 AM,10:15 AM
143,VAST,TVCG,VAST,Exploranative Code Quality Documents,"Haris Mumtaz, Shahid Latif, Fabian Beck, Daniel Weiskopf",https://arxiv.org/pdf/1907.11481.pdf,"Good code quality is a prerequisite for efficiently developing maintainable software. In this paper, we present a novel approach to generate exploranative (explanatory and exploratory) data-driven documents that report code quality in an interactive, exploratory environment. We employ a template-based natural language generation method to create textual explanations about the code quality, dependent on data from software metrics. The interactive document is enriched by different kinds of visualization, including parallel coordinates plots and scatterplots for data exploration and graphics embedded into text. We devise an interaction model that allows users to explore code quality with consistent linking between text and visualizations; through integrated explanatory text, users are taught background knowledge about code quality aspects. Our approach to interactive documents was developed in a design study process that included software engineering and visual analytics experts. Although the solution is specific to the software engineering scenario, we discuss how the concept could generalize to multivariate data and report lessons learned in a broader scope.",,,,,,vimeo 360154571,,,2019,2019,Ballroom B,Thursday,Vis for Software and Systems,24-Oct,10:15 AM,10:30 AM
144,VAST,TVCG,VAST,GUIRO: User-Guided Matrix Reordering,"Michael Behrisch, Tobias Schreck, Hanspeter Pfister",https://osf.io/x46gh/,"Matrix representations are one of the main established and empirically proven to be effective visualization techniques for relational (or network) data. However, matrices —similar to node-link diagrams— are most effective if their layout reveals the underlying data topology. Given the many developed algorithms, a practical problem arises: <em>“Which matrix reordering algorithm should I choose for my dataset at hand?”</em> To make matters worse, different reordering algorithms applied to the same dataset may let significantly different visual matrix patterns emerge. This leads to the question of trustworthiness and explainability of these fully automated, often heuristic, black-box processes. We present GUIRO, a Visual Analytics system that helps novices, network analysts, and algorithm designers to open the black-box. Users can investigate the usefulness and expressiveness of 70 accessible matrix reordering algorithms. For network analysts, we introduce a novel model space representation and two interaction techniques for a user-guided reordering of rows or columns, and especially groups thereof (submatrix reordering). These novel techniques contribute to the understanding of the global and local dataset topology. We support algorithm designers by giving them access to 16 reordering quality metrics and visual exploration means for comparing reordering implementations on a row/column permutation level. We evaluated GUIRO in a guided explorative user study with 12 subjects, a case study demonstrating its usefulness in a real-world scenario, and through an expert study gathering feedback on our design decisions. We found that our proposed methods help even inexperienced users to understand matrix patterns and allow a user-guided steering of reordering algorithms. GUIRO helps to increase the transparency of matrix reordering algorithms, thus helping a broad range of users to get a better insight into the complex reordering process, in turn supporting data and reordering algorithm insights.",,,,,,youtube kJ74LK4jvLM,,10.1109/TVCG.2019.2934300,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,4:10 PM,4:25 PM
145,SciVis,TVCG,SciVis,LassoNet: Deep Lasso-Selection of 3D Point Clouds,"Zhutian Chen, Wei Zeng, ZhiGuang Yang, Lingyun Yu, Chi-Wing Fu, Huamin Qu",https://arxiv.org/pdf/1907.13538.pdf,"Selection is a fundamental task in exploratory analysis and visualization of 3D point clouds. Prior researches on selection methods were developed mainly based on heuristics such as local point density, thus limiting their applicability in general data. Specific challenges root in the great variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint (e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this work, we introduce LassoNet, a new deep neural network for lasso selection of 3D point clouds, attempting to learn a latent mapping from viewpoint and lasso to point cloud regions. To achieve this, we couple user-target points with viewpoint and lasso information through 3D coordinate transform and naive selection, and improve the method scalability via an intention filtering and farthest point sampling. A hierarchical network is trained using a dataset with over 30K lasso-selection records on two different point cloud data. We conduct a formal user study to compare LassoNet with two state-of-the-art lasso-selection methods. The evaluations confirm that our approach improves the selection effectiveness and efficiency across different combinations of 3D point clouds, viewpoints, and lasso selections. Project Website: <a href=""https://lassonet.github.io"">https://lassonet.github.io</a>",,,,,,vimeo 359999060,,10.1109/TVCG.2019.2934332,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,4:25 PM,4:40 PM
146,SciVis,TVCG,SciVis,TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization,"Jun Han, Chaoli Wang",,,,,,,,vimeo 359998660,,10.1109/TVCG.2019.2934255,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,4:40 PM,4:55 PM
147,InfoVis,TVCG,InfoVis,GenerativeMap: Visualization and Exploration of Dynamic Density Maps via Generative Learning Model,"Chen Chen, Changbo Wang, Xue Bai, Peiying Zhang, Chenhui Li",,,,,,,,vimeo 360050049,,10.1109/TVCG.2019.2934806,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,4:55 PM,5:10 PM
148,VAST,TVCG,VAST,Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,"Robert Krüger, Johanna Beyer, Won-Dong Jang, Nam Wook Kim, Artem Sokolov, Peter Sorger, Hanspeter Pfister",https://www.biorxiv.org/content/biorxiv/early/2019/08/02/722918.full.pdf,"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 10<sup>9</sup> or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.",,,,,,vimeo 360156054,,,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,5:10 PM,5:25 PM
149,VAST,TVCG,VAST,Steering Deep Sequence Model with Prototypes,"Yao Ming, Panpan Xu, Furui Cheng, Huamin Qu, Liu Ren",,,,,,,,,,,2019,2019,Ballroom A,Tuesday,VIS Meets Machine Learning,22-Oct,5:25 PM,5:40 PM
150,InfoVis,TVCG,InfoVis,CerebroVis: Designing an Abstract yet Spatially Contextualized Cerebral Arteries Network Visualization,"Aditeya Pandey, Harsh Shukla, Geoffrey S. Young, Lei Qin, Amir A. Zamani, Liangge Hsu, Raymond Huang, Cody Dunne, Michelle A. Borkin",https://osf.io/63y5c/,"Blood circulation in the human brain is supplied through a network of cerebral arteries. If a clinician suspects a patient has a stroke or other cerebrovascular condition, they order imaging tests. Neuroradiologists visually search the resulting scans for abnormalities. Their visual search tasks correspond to the abstract network analysis tasks of browsing and path following. To assist neuroradiologists in identifying cerebral artery abnormalities, we designed CerebroVis, a novel abstract—yet spatially contextualized—cerebral artery network visualization. In this design study, we contribute a novel framing and definition of the cerebral artery system in terms of network theory and characterize neuroradiologist domain goals as abstract visualization and network analysis tasks. Through an iterative, user-centered design process we developed an abstract network layout technique which incorporates cerebral artery spatial context. The abstract visualization enables increased domain task performance over 3D geometry representations, while including spatial context helps preserve the user’s mental map of the underlying geometry. We provide open source implementations of our network layout technique and prototype cerebral artery visualization tool. We demonstrate the robustness of our technique by successfully laying out 61 open source brain scans. We evaluate the effectiveness of our layout through a mixed methods study with three neuroradiologists. In a formative controlled experiment our study participants used CerebroVis and a conventional 3D visualization to examine real cerebral artery imaging data to identify a simulated intracranial artery stenosis. Participants were more accurate at identifying stenoses using CerebroVis (absolute risk difference 13%). A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/e5sxt.",,,https://osf.io/e5sxt/,https://osf.io/2bv36/,https://osf.io/2bv36/,youtube E1-4p1V6uaw,,,2019,2019,Ballroom A,Thursday,Visualization in Medicine,24-Oct,4:10 PM,4:25 PM
151,SciVis,TVCG,SciVis,Cohort-based T-SSIM Visual Computing for Radiation Therapy Prediction and Exploration,"Andrew Wentzel, Peter Haula, Timothy Basil Luciani, Baher Elgohari, Hesham Elhalawani, Guadalupe Canahuate, David M. Vock, Clifton David Fuller, G. Elisabeta Marai",https://arxiv.org/pdf/1907.05919.pdf,"We describe a visual computing approach to radiation therapy (RT) planning, based on spatial similarity within a patient cohort. In radiotherapy for head and neck cancer treatment, dosage to organs at risk surrounding a tumor is a large cause of treatment toxicity. Along with the availability of patient repositories, this situation has lead to clinician interest in understanding and predicting RT outcomes based on previously treated similar patients. To enable this type of analysis, we introduce a novel topology-based spatial similarity measure, T-SSIM, and a predictive algorithm based on this similarity measure. We couple the algorithm with a visual steering interface that intertwines visual encodings for the spatial data and statistical results, including a novel parallel-marker encoding that is spatially aware. We report quantitative results on a cohort of 165 patients, as well as a qualitative evaluation with domain experts in radiation oncology, data management, biostatistics, and medical imaging, who are collaborating remotely.",,,,,,vimeo 359999477,,,2019,2019,Ballroom A,Thursday,Visualization in Medicine,24-Oct,4:25 PM,4:40 PM
152,SciVis,TVCG,SciVis,DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D Lung Models from Single-View Projections by Deep Deformation Network,"Yifan Wang, Zichun Zhong, Jing Hua",https://arxiv.org/pdf/1907.09375.pdf,"This paper introduces a deep neural network based method, i.e., DeepOrganNet, to generate and visualize fully high-fidelity 3D / 4D organ geometric models from single-view medical images with complicated background in real time. Traditional 3D / 4D medical image reconstruction requires near hundreds of projections, which cost insufferable computational time and deliver undesirable high imaging / radiation dose to human subjects. Moreover, it always needs further notorious processes to segment or extract the accurate 3D organ models subsequently. The computational time and imaging dose can be reduced by decreasing the number of projections, but the reconstructed image quality is degraded accordingly. To our knowledge, there is no method directly and explicitly reconstructing multiple 3D organ meshes from a single 2D medical grayscale image on the fly. Given single-view 2D medical images, e.g., 3D / 4D-CT projections or X-ray images, our end-to-end DeepOrganNet framework can efficiently and effectively reconstruct 3D / 4D lung models with a variety of geometric shapes by learning the smooth deformation fields from multiple templates based on a trivariate tensor-product deformation technique, leveraging an informative latent descriptor extracted from input 2D images. The proposed method can guarantee to generate high-quality and high-fidelity manifold meshes for 3D / 4D lung models; while, all current deep learning based approaches on the shape reconstruction from a single image cannot. The major contributions of this work are to accurately reconstruct the 3D organ shapes from 2D single-view projection, significantly improve the procedure time to allow on-the-fly visualization, and dramatically reduce the imaging dose for human subjects. Experimental results are evaluated and compared with the traditional reconstruction method and the state-of-the-art in deep learning, by using extensive 3D and 4D examples, including both synthetic phantom and real patient datasets. The efficiency of the proposed method shows that it only needs several milliseconds to generate organ meshes with 10K vertices, which has a great potential to be used in real-time image guided radiation therapy (IGRT).",,,,,,vimeo 359999320,,,2019,2019,Ballroom A,Thursday,Visualization in Medicine,24-Oct,4:40 PM,4:55 PM
153,SciVis,TVCG,SciVis,Temporal Views of Flattened Mitral Valve Geometries,"Pepe Eulzer, Sandy Engelhardt, Nils Lichtenberg, Raffaele de Simone, Kai Lawonn",,,,,,,,vimeo 359999188,,10.1109/TVCG.2019.2934337,2019,2019,Ballroom A,Thursday,Visualization in Medicine,24-Oct,4:55 PM,5:10 PM
154,VAST,TVCG,VAST,Motion Browser: Visualizing and Understanding Complex Upper Limb Movement Under Obstetrical Brachial Plexus Injuries,"Gromit Yeuk-Yin Chan, Luis Gustavo Nonato, Alice Chu, Preeti Raghavan, Viswanath Aluru, Claudio Silva",https://arxiv.org/pdf/1907.09146.pdf,"The brachial plexus is a complex network of peripheral nerves that enables sensing from and control of the movements of the arms and hand. Nowadays, the coordination between the muscles to generate simple movements is still not well understood, hindering the knowledge of how to best treat patients with this type of peripheral nerve injury. To acquire enough information for medical data analysis, physicians conduct motion analysis assessments with patients to produce a rich dataset of electromyographic signals from multiple muscles recorded with joint movements during real-world tasks. However, tools for the analysis and visualization of the data in a succinct and interpretable manner are currently not available. Without the ability to integrate, compare, and compute multiple data sources in one platform, physicians can only compute simple statistical values to describe patient’s behavior vaguely, which limits the possibility to answer clinical questions and generate hypotheses for research. To address this challenge, we have developed MOTION BROWSER, an interactive visual analytics system which provides an efficient framework to extract and compare muscle activity patterns from the patient’s limbs and coordinated views to help users analyze muscle signals, motion data, and video information to address different tasks. The system was developed as a result of a collaborative endeavor between computer scientists and orthopedic surgery and rehabilitation physicians. We present case studies showing physicians can utilize the information displayed to understand how individuals coordinate their muscles to initiate appropriate treatment and generate new hypotheses for future research.",,,,,,vimeo 360155635,,,2019,2019,Ballroom A,Thursday,Visualization in Medicine,24-Oct,5:10 PM,5:25 PM
155,SciVis,TVCG,SciVis,Void-and-Cluster Sampling of Large Scattered Data and Trajectories,"Tobias Rapp, Christoph Peters, Carsten Dachsbacher",https://arxiv.org/pdf/1907.05073.pdf,"We propose a data reduction technique for scattered data based on statistical sampling. Our void-and-cluster sampling technique finds a representative subset that is optimally distributed in the spatial domain with respect to the blue noise property. In addition, it can adapt to a given density function, which we use to sample regions of high complexity in the multivariate value domain more densely. Moreover, our sampling technique implicitly defines an ordering on the samples that enables progressive data loading and a continuous level-of-detail representation. We extend our technique to sample time-dependent trajectories, for example pathlines in a time interval, using an efficient and iterative approach. Furthermore, we introduce a local and continuous error measure to quantify how well a set of samples represents the original dataset. We apply this error measure during sampling to guide the number of samples that are taken. Finally, we use this error measure and other quantities to evaluate the quality, performance, and scalability of our algorithm.",,,,,,vimeo 359999170,,10.1109/TVCG.2019.2934335,2019,2019,Ballroom B,Thursday,Volume Visualization,24-Oct,10:50 AM,11:05 AM
156,TVCG,TVCG,SciVis,FeatureLego: Volume Exploration Using Exhaustive Clustering of Super-Voxels,"Shreeraj Jadhav, Saad Nadeem, Arie Kaufman",https://arxiv.org/pdf/1810.05220.pdf,"We present a volume exploration framework, FeatureLego, that uses a novel voxel clustering approach for efficient selection of semantic features. We partition the input volume into a set of compact super-voxels that represent the finest selection granularity. We then perform an exhaustive clustering of these super-voxels using a graph-based clustering method. Unlike the prevalent brute-force parameter sampling approaches, we propose an efficient algorithm to perform this exhaustive clustering. By computing an exhaustive set of clusters, we aim to capture as many boundaries as possible and ensure that the user has sufficient options for efficiently selecting semantically relevant features. Furthermore, we merge all the computed clusters into a single tree of meta-clusters that can be used for hierarchical exploration. We implement an intuitive user-interface to interactively explore volumes using our clustering approach. Finally, we show the effectiveness of our framework on multiple real-world datasets of different modalities.",,,,,,vimeo 364568860,,,?,2019,Ballroom B,Thursday,Volume Visualization,24-Oct,11:05 AM,11:20 AM
157,TVCG,TVCG,SciVis,Interactive Visualization and On-Demand Processing of Large Volume Data: A Fully GPU-Based Out-Of-Core Approach,"Jonathan Sarton, Nicolas Courilleau, Yannick Remion, Laurent Lucas",https://hal.univ-reims.fr/hal-01705431/document,"In a wide range of scientific fields, 3D datasets production capabilities have widely evolved in recent years, especially with the rapid increase in their size. As a result, many large-scale applications, including visualization or processing, have become challenging to address. A solution to this issue lies in providing out-of-core algorithms specifically designed to handle datasets significantly larger than memory. In this article, we present a new approach that extends the broad interactive addressing principles already established in the field of out-of-core volume rendering on GPUs to allow on-demand processing during the visualization stage. We propose a pipeline designed to manage data as regular 3D grids regardless of the underlying application. It relies on a caching approach with a virtual memory addressing system coupled to an efficient parallel management on GPU to provide efficient access to data in interactive time. It allows any visualization or processing application to leverage the flexibility of its structure by managing multi-modality datasets. Furthermore, we show that our system delivers good performance on a single standard PC with low memory budget on the GPU.",,,,,,vimeo 364569226,,10.1109/TVCG.2019.2912752,?,2019,Ballroom B,Thursday,Volume Visualization,24-Oct,11:20 AM,11:35 AM
158,TVCG,TVCG,SciVis,"Scientific visualization, opacity optimization, Fourier approximation","Irene Baeza Rojo, Markus Gross, Tobias Günther",,,,,,,,,,,?,2019,Ballroom B,Thursday,Volume Visualization,24-Oct,11:35 AM,11:50 AM
159,TVCG,TVCG,SciVis,Ray-based Exploration of Large Time-varying Volume Data Using Proxy Per-ray Distributions,"Ko-Chih Wang, Tzu-Hsuan Wei, Shareef Naeem, Han-Wei Shen",,,,,,,,vimeo 364569304,,,?,2019,Ballroom B,Thursday,Volume Visualization,24-Oct,11:50 AM,12:05 PM
160,InfoVis,TVCG,InfoVis,The Perceptual Proxies of Visual Comparison,"Nicole Jardine, Brian David Ondov, Niklas Elmqvist, Steven Franconeri",https://osf.io/ykmt7,"Perceptual tasks in visualizations often involve comparisons. Of two sets of values depicted in two charts, which set had values that were the highest overall? Which had the widest range? Prior empirical work found that the performance on different visual comparison tasks (e.g., “biggest delta”, “biggest correlation”) varied widely across different combinations of marks and spatial arrangements. In this paper, we expand upon these combinations in an empirical evaluation of two new comparison tasks: the “biggest mean” and “biggest range” between two sets of values. We used a staircase procedure to titrate the difficulty of the data comparison to assess which arrangements produced the most precise comparisons for each task. We find visual comparisons of biggest mean and biggest range are supported by some chart arrangements more than others, and that this pattern is substantially different from the pattern for other tasks. To synthesize these dissonant findings, we argue that we must understand which features of a visualization are actually used by the human visual system to solve a given task. We call these perceptual proxies. For example, when comparing the means of two bar charts, the visual system might use a “Mean length” proxy that isolates the actual lengths of the bars and then constructs a true average across these lengths. Alternatively, it might use a “Hull Area” proxy that perceives an implied hull bounded by the bars of each chart and then compares the areas of these hulls. We propose a series of potential proxies across different tasks, marks, and spatial arrangements. Simple models of these proxies can be empirically evaluated for their explanatory power by matching their performance to human performance across these marks, arrangements, and tasks. We use this process to highlight candidates for perceptual proxies that might scale more broadly to explain performance in visual comparison.",,,,https://osf.io/uenzd,,vimeo 360050277,,10.1109/TVCG.2019.2934786,2019,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,4:10 PM,4:25 PM
161,InfoVis,TVCG,InfoVis,BarcodeTree: Scalable Comparison of Multiple Hierarchies,"Guozheng Li, Yu Zhang, Yu Dong, Jie Liang, Jinson Zhang, Jinsong Wang, Michael McGuffin, Xiaoru Yuan",,,,,,,,vimeo 360050493,,,2019,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,4:25 PM,4:40 PM
162,InfoVis,TVCG,InfoVis,Comparison of Radial and Linear charts for Visualizing Daily Patterns,"Manuela Waldner, Alexandra Diehl, Denis Gracanin, Rainer Splechtna, Claudio Delrieux, Kresimir Matkovic",,,,,,,,vimeo 360050294,,,2019,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,4:40 PM,4:55 PM
163,InfoVis,TVCG,InfoVis,Separating the wheat from the chaff: Comparative visual cues for reliable diagnostics of competing models,"Aritra Dasgupta, Hong Wang, Nancy D O'Brien, Susannah Marie Burrows",,,,,,,,,,,2019,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,4:55 PM,5:10 PM
164,TVCG,TVCG,InfoVis,Aggregated Dendrograms for Visual Comparison Between Many Phylogenetic Trees,"Zipeng Liu, Shing Hei Zhan, Tamara Munzner",,,,,,,,vimeo 364568553,,10.1109/TVCG.2019.2898186,?,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,5:10 PM,5:25 PM
165,VAST,TVCG,VAST,STBins: Visual Tracking and Comparison of Multiple Data Sequences using Temporal Binning,"Ji Qi, Vincent Bloemen, Shihan Wang, Jarke van Wijk, Huub van de Wetering",,,,,,,,vimeo 360155660,,,2019,2019,Ballroom C,Thursday,What's the Difference?,24-Oct,5:25 PM,5:40 PM
166,TVCG,TVCG,VAST,LDA Ensembles for Interactive Exploration and Categorization of Behaviors,"Siming Chen, Natalia Andrienko, Gennady Andrienko, Linara Adilova, Jeremie Barlet, Joerg Kindermann, Phong H. Nguyen, Olivier Thonnard, Cagatay Turkay",http://openaccess.city.ac.uk/id/eprint/21875/1/LDA_Ensembles_for_Interactive_Exploration_and_Categorization_of_Behaviors.pdf,"We define <strong>behavior</strong> as a set of <strong>actions</strong> performed by some actor during a period of time. We consider the problem of analyzing a large collection of behaviors by multiple actors, more specifically, identifying typical behaviors and spotting anomalous behaviors. We propose an approach leveraging topic modeling techniques – LDA (Latent Dirichlet Allocation) Ensembles – to represent categories of typical behaviors by topics that are obtained through topic modeling a behavior collection. When such methods are applied to text in natural languages, the quality of the extracted topics are usually judged based on the semantic relatedness of the terms pertinent to the topics. This criterion, however, is not necessarily applicable to topics extracted from non-textual data, such as action sets, since relationships between actions may not be obvious. We have developed a suite of visual and interactive techniques supporting the construction of an appropriate combination of topics based on other criteria, such as distinctiveness and coverage of the behavior set. Two case studies on analyzing operation behaviors in the security management system and visiting behaviors in an amusement park, and the expert evaluation of the first case study demonstrate the effectiveness of our approach.",,,,,,vimeo 364568366,,10.1109/TVCG.2019.2904069,?,2019,Ballroom B,Thursday,Words & Documents,24-Oct,4:10 PM,4:25 PM
167,InfoVis,TVCG,InfoVis,ShapeWordle: Tailoring Wordles using Shape-aware Archimedean Spirals,"Yunhai Wang, Xiaowei Chu, Kaiyi Zhang, Chen Bao, Xiaotong Li, Jian Zhang, Christophe Hurter, Chi-Wing Fu, Oliver Deussen",,,,,,,,vimeo 360050251,,,2019,2019,Ballroom B,Thursday,Words & Documents,24-Oct,4:25 PM,4:40 PM
168,VAST,TVCG,VAST,Semantic Concept Spaces: Guided Topic Model Refinement using Word-Embedding Projections,"Mennatallah El-Assady, Rebecca Kehlbeck, Christopher Collins, Daniel Keim, Oliver Deussen",https://arxiv.org/pdf/1908.00475.pdf,"We present a framework that allows users to incorporate the semantics of their domain knowledge for topic model refinement while remaining model-agnostic. Our approach enables users to (1) understand the semantic space of the model, (2) identify regions of potential conflicts and problems, and (3) readjust the semantic relation of concepts based on their understanding, directly influencing the topic modeling. These tasks are supported by an interactive visual analytics workspace that uses word-embedding projections to define concept regions which can then be refined. The user-refined concepts are independent of a particular document collection and can be transferred to related corpora. All user interactions within the concept space directly affect the semantic relations of the underlying vector space model, which, in turn, change the topic modeling. In addition to direct manipulation, our system guides the users’ decisionmaking process through recommended interactions that point out potential improvements. This targeted refinement aims at minimizing the feedback required for an efficient human-in-the-loop process. We confirm the improvements achieved through our approach in two user studies that show topic model quality improvements through our visual knowledge externalization and learning process.",,,,,,vimeo 360154204,,10.1109/TVCG.2019.2934654,2019,2019,Ballroom B,Thursday,Words & Documents,24-Oct,4:40 PM,4:55 PM
169,VAST,VAST,VAST,VIANA: Visual Interactive Annotation of Argumentation,"Fabian Sperrle, Rita Sevastjanova, Rebecca Kehlbeck, Mennatallah El-Assady",https://arxiv.org/pdf/1907.12413.pdf,"Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.",https://viana.lingvis.io/,,,,,vimeo 360154233,,,2019,2019,Ballroom B,Thursday,Words & Documents,24-Oct,4:55 PM,5:10 PM
170,TVCG,TVCG,VAST,Topic-based Exploration and Embedded Visualizations for Research Idea Generation,"Hua Guo, David H. Laidlaw",,,,,,,,vimeo 364568027,,10.1109/TVCG.2018.2873011,?,2019,Ballroom B,Thursday,Words & Documents,24-Oct,5:10 PM,5:25 PM
171,TVCG,TVCG,InfoVis,An Evaluation of Semantically Grouped Word Cloud Designs,"Marti A. Hearst, Emily Pedersen, Lekha Patil, Elsie Lee, Paul Laskowski, Steven Franconeri",https://osf.io/3eutf/,"Word clouds continue to be a popular tool for summarizing textual information, despite their well-documented deficiencies for analytic tasks. Much of their popularity rests on their playful visual appeal. In this paper, we present the results of a series of controlled experiments that show that layouts in which words are arranged into semantically and visually distinct zones are more effective for understanding the underlying topics than standard word cloud layouts. White space separators and/or spatially grouped color coding led to significantly stronger understanding of the underlying topics compared to a standard Wordle layout, while simultaneously scoring higher on measures of aesthetic appeal. This work is an advance on prior research on semantic layouts for word clouds because that prior work has either not ensured that the different semantic groupings are visually or semantically distinct, or has not performed usability studies. An additional contribution of this work is the development of a dataset for a semantic category identification task that can be used for replication of these results or future evaluations of word cloud designs.",,,,,,vimeo 364568578,,10.1109/TVCG.2019.2904683,?,2019,Ballroom B,Thursday,Words & Documents,24-Oct,5:25 PM,5:40 PM
172,VAST,TVCG,VAST,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,"Thilo Spinner, Udo Schlegel, Hanna Schaefer, Mennatallah El-Assady",https://arxiv.org/pdf/1908.00087.pdf,"We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.",https://explainer.ai/,,,,,vimeo 360154764,vimeo 368699132,,2019,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,9:00 AM,9:15 AM
173,VAST,TVCG,VAST,Explaining Vulnerabilities to Adversarial Machine Learning through Visual Analytics,"Yuxin Ma, Tiankai Xie, Jundong Li, Ross Maciejewski",https://arxiv.org/pdf/1907.07296.pdf,"Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.",,,,,https://github.com/VADERASU/visual-analytics-adversarial-attacks,vimeo 360154813,vimeo 369214358,,2019,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,9:15 AM,9:30 AM
174,VAST,TVCG,VAST,FairSight: Visual Analytics for Fairness in Decision Making,"Yongsu Ahn, Yu-Ru Lin",https://arxiv.org/pdf/1908.00176.pdf,"Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions – understanding, measuring, diagnosing and mitigating biases – that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.",,,,,,vimeo 360155342,vimeo 368701050,10.1109/TVCG.2019.2934262,2019,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,9:30 AM,9:45 AM
175,VAST,TVCG,VAST,Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,"Fred Hohman, Haekyu Park, Caleb Robinson, Duen Horng Chau",https://arxiv.org/pdf/1904.02323.pdf,"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present SUMMIT, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. SUMMIT introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. SUMMIT combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model’s outcomes. SUMMIT scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where SUMMIT helps us discover multiple surprising insights into a prevalent, large-scale image classifier’s learned representations and informs future neural network architecture design. The SUMMIT visualization runs in modern web browsers and is open-sourced.",http://fredhohman.com/summit,,,,https://github.com/fredhohman/summit,vimeo 360154453,vimeo 368704428,10.1109/TVCG.2019.2934659,2019,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,9:45 AM,10:00 AM
176,VAST,VAST,VAST,FairVis: Visual Analytics for Discovering Intersectional Bias in Machine Learning,"Àngel Alexander Cabrera, Will Epperson, Fred Hohman, Minsuk Kahng, Jamie Morgenstern, Duen Horng Chau",https://arxiv.org/pdf/1904.05419.pdf,"The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS’s coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.",https://poloclub.github.io/FairVis/,,,,,vimeo 360155233,vimeo 368702211,,2019,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,10:00 AM,10:15 AM
177,TVCG,TVCG,VAST,Visual Genealogy of Deep Neural Networks,"Qianwen Wang, Jun Yuan, Shuxin Chen, Hang Su, Huamin Qu, Shixia Liu",,,,,,,,vimeo 364568338,,10.1109/TVCG.2019.2921323,?,2019,Ballroom A,Thursday,XAI and Fairness,24-Oct,10:15 AM,10:30 AM
178,CG&A,CG&A,CG&A,A Walk Among the Data: Exploration and Anthropomorphism in Immersive Unit Visualizations,"Alexander Ivanov, Kurtis Danyluk, Christian Jacob, Wesley Willett",,,,,,,,vimeo 359999645,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,10:50 AM,11:05 AM
179,CG&A,CG&A,CG&A,Immersive Analytics Lessons from the Electronic Visualization Laboratory: a 25 Year Perspective,"G. Elisabeta Marai, Jason Leigh, Andrew Johnson",,,,,,,,vimeo 359999721,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,11:05 AM,11:20 AM
180,CG&A,CG&A,CG&A,Comfortable Immersive Analytics with the VirtualDesk Metaphor,"Jorge A. Wagner Filho, Carla M. D. S. Freitas, Luciana Nedel",,,,,,,,vimeo 359999785,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,11:20 AM,11:35 AM
181,CG&A,CG&A,CG&A,Augmented Reality Graph Visualizations - Investigation of Visual Styles in 3D Node-Link Diagrams,"Wolfgang Büschel, Stefan Vogt, Raimund Dachselt",,,,,,,,vimeo 359999817,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,11:35 AM,11:50 AM
182,CG&A,CG&A,CG&A,Visualization and the Digital Humanities:,"Adam James Bradley, Mennatallah El-Assady, Katharine Coles, Eric Alexander, Min Chen, Christopher Collins, Stefan Jänicke, David Joseph Wrisley",https://ora.ox.ac.uk/objects/uuid:d89c5ef6-84f3-4b6d-9064-0c6e419e1a35/download_file?file_format=pdf&safe_filename=%255BVIS4DH%255D%2BCG%2526A_Revisions_Aug_1_2018.pdf&type_of_work=Journal+article,"For the past two years, researchers from the visualization community and the digital humanities have come together at the IEEE VIS conference to discuss how both disciplines can work together to push research goals in their respective disciplines. This process has been both fruitful and challenging, bringing to light how different knowledge is created in the sciences and the humanities, but also how methodological differences can be traversed to produce truly interdisciplinary work. In this paper, we present our experiences as a group and our individual experiences as humanists and computer scientists. While we explore a broad spectrum of ideas, our goals are strikingly similar: to understand the processes and motivations of each other’s work better as a way of increasing self-reflection on our own.",,,,,,,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,11:50 AM,12:05 PM
183,CG&A,CG&A,CG&A,Graphoto: Aesthetically Pleasing Charts for Casual Information Visualization,"Ji Hwan Park, Arie Kaufman, Klaus Mueller",,,,,,,,vimeo 359999850,,,?,2019,Room 8+15,Wednesday,CG&A Session 1,23-Oct,12:05 PM,12:20 PM
184,CG&A,CG&A,CG&A,VitalVizor: A Visual Analytics System for Studying Urban Vitality,"Wei Zeng, Yu Ye",,,,,,,,vimeo 359999892,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,10:50 AM,11:05 AM
185,CG&A,CG&A,CG&A,Designing Effective Visual Interactive Systems despite Sparse Availability of Domain Information,"Benjamin Karer, Alina Freund, Michael Horst, Inga Scheler, Thomas Kossurok, Franz-Josef Brandt",,,,,,,,vimeo 359999909,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,11:05 AM,11:20 AM
186,CG&A,CG&A,CG&A,Mapping and Visualizing Deep-Learning Urban Beautification,"Tobias Kauer, Sagar Joglekar, Miriam Redi, Luca Maria Aiello, Daniele Quercia",,,,,,,,vimeo 359999969,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,11:20 AM,11:35 AM
187,CG&A,CG&A,CG&A,RNNbow: Visualizing Learning Via Backpropagation Gradients in RNNs,"Dylan Cashman, Geneviève Patterson, Abigail Mosca, Nathan Watts, Shannon Robinson, Remco Chang",,,,,,,,vimeo 359999999,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,11:35 AM,11:50 AM
188,CG&A,CG&A,CG&A,PUMA-V: Optimizing Parallel Code Performance Through Interactive Visualization,"Eric Papenhausen, M. Harper Langston, Benoit Meister, Richard A. Lethin, Klaus Mueller",,,,,,,,vimeo 360000013,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,11:50 AM,12:05 PM
189,CG&A,CG&A,CG&A,Cross-Platform Ubiquitous Volume Rendering Using Programmable Shaders in VTK for Scientific and Medical Visualization,"Aashish Chaudhary, Sankhesh J. Jhaveri, Alvaro Sanchez, Lisa S. Avila, Kenneth M. Martin, Allison Vacanti, Marcus D. Hanwell, Will Schroeder",,,,,,,,vimeo 360000042,,,?,2019,Room 2+3,Thursday,CG&A Session 2,24-Oct,12:05 PM,12:20 PM
190,Short,Short,Short,Graph-assisted Visualization of Microvascular Networks,"Pavel Govyadinov, Tasha Womack, Jason Eriksen, David Mayerich, Guoning Chen",,,,,,,,vimeo 363452229,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,2:35 PM,2:45 PM
191,Short,Short,Short,Learning Vis Tools: Teaching Data Visualization Tutorials,"Leo Yu-Ho Lo, Yao Ming, Huamin Qu",https://arxiv.org/pdf/1907.08796.pdf,"Teaching and advocating data visualization are among the most important activities in the visualization community. With growing interest in data analysis from business and science professionals, data visualization courses attract students across different disciplines. However, comprehensive visualization training requires students to have a certain level of proficiency in programming, a requirement that imposes challenges on both teachers and students. With recent developments in visualization tools, we have managed to overcome these obstacles by teaching a wide range of visualization and supporting tools. Starting with GUI-based visualization tools and data analysis with Python, students put visualization knowledge into practice with increasing amounts of programming. At the end of the course, students can design and implement visualizations with D3 and other programming-based visualization tools. Throughout the course, we continuously collect student feedback and refine the teaching materials. This paper documents our teaching methods and considerations when designing the teaching materials.",https://github.com/leoyuholo/learning-vis-tools,,,,,vimeo 363041257,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,2:45 PM,2:55 PM
192,Short,Short,Short,Sociotechnical Considerations for Accessible Visualization Design,"Alan Lundgard, Crystal Lee, Arvind Satyanarayan",https://arxiv.org/ftp/arxiv/papers/1909/1909.05118.pdf,"Accessibility—the process of designing for people with disabilities (PWD)—is an important but under-explored challenge in the visualization research community. Without careful attention, and if PWD are not included as equal participants throughout the process, there is a danger of perpetuating a vision-first approach to accessible design that marginalizes the lived experience of disability (e.g., by creating overly simplistic “sensory translations” that map visual to non-visual modalities in a one-to-one fashion). In this paper, we present a set of sociotechnical considerations for research in accessible visualization design, drawing on literature in disability studies, tactile information systems, and participatory methods. We identify that using state-of-the-art technologies may introduce more barriers to access than they remove, and that expectations of research novelty may not produce outcomes well-aligned with the needs of disability communities. Instead, to promote a more inclusive design process, we emphasize the importance of clearly communicating goals, following existing accessibility guidelines, and treating PWD as equal participants who are compensated for their specialized skills. To illustrate how these considerations can be applied in practice, we discuss a case study of an inclusive design workshop held in collaboration with the Perkins School for the Blind.",,,,,,vimeo 363041501,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,2:55 PM,3:05 PM
193,Short,Short,Short,How Expensive is the Wine?Toward Interface Defaults for Vague Modifiers in Natural Language Interfaces for Visual Analysis,"Marti Hearst, Melanie Tory, Vidya Setlur",,,,,,,,,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,3:05 PM,3:15 PM
194,Short,Short,Short,VisWall: Visual Data Exploration using Direct Combination on Large Touch Displays,"Mallika Agarwal, Arjun Srinivasan, John Stasko",,,,,,,,vimeo 363042417,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,3:15 PM,3:25 PM
195,Short,Short,Short,EasyPZ.js: Interaction Binding For Pan and Zoom Visualizations,"Michail Schwab, James Tompkin, Jeff Huang, Michelle A. Borkin",,,,,,,,vimeo 363041807,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,3:25 PM,3:35 PM
196,Short,Short,Short,Would You Like A Chart With That? Incorporating Visualizations into Conversational Interfaces,"Marti Hearst, Melanie Tory",,,,,,,,vimeo 363042343,,,?,2019,Room 1,Tuesday,Short Papers: Novel Interfaces,22-Oct,3:35 PM,3:45 PM
197,Short,Short,Short,Visualization Assessment: A Machine Learning Approach,"Xin Fu, Yun Wang, Haoyu Dong, Weiwei Cui, Haidong Zhang",,,,,,,,vimeo 363041569,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,2:20 PM,2:30 PM
198,Short,Short,Short,A Deep Learning Approach to Selecting Representative Time Steps for Time-Varying Multivariate Data,"William P. Porter, Yunhao Xing, Blaise R von Ohlen, Jun Han, Chaoli Wang",,,,,,,,vimeo 363040865,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,2:30 PM,2:40 PM
199,Short,Short,Short,Disentangled Representation of Data Distributions in Scatterplots,"Jaemin Jo, Jinwook Seo",,,,,,,,vimeo 363042207,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,2:40 PM,2:50 PM
200,Short,Short,Short,Toward Perception-based Evaluation of Clustering Techniques for Visual Analytics,"Michaël Aupetit, Michael Sedlmair, Mostafa M. Abbas, Halima Bensmail",,  ,,,,,,vimeo 363452065,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,2:50 PM,3:00 PM
201,Short,Short,Short,SANVis: Visual Analytics for Understanding Self Attention Networks,"Cheonbok Park, Inyoup Na, Yongjang Jo, Sungbok Shin, Yoo Jaehyo, Bum Chul Kwon, Jian Zhao, Hyungjong Noh, Yeonsoo Lee, Jaegul Choo",https://arxiv.org/pdf/1909.09595.pdf,"Attention networks, a deep neural network architecture inspired by humans’ attention mechanism, have seen significant success in image captioning, machine translation, and many other applications. Recently, they have been further evolved into an advanced approach called multi-head self-attention networks, which can encode a set of input vectors, e.g., word vectors in a sentence, into another set of vectors. Such encoding aims at simultaneously capturing diverse syntactic and semantic features within a set, each of which corresponds to a particular attention head, forming altogether multi-head attention. Meanwhile, the increased model complexity prevents users from easily understanding and manipulating the inner workings of models. To tackle the challenges, we present a visual analytics system called SANVis, which helps users understand the behaviors and the characteristics of multi-head self-attention networks. Using a state-of-the-art self-attention model called Transformer, we demonstrate usage scenarios of SANVis in machine translation tasks. Our system is available at http://short.sanvis.org.",http://short.sanvis.org/,,,,,vimeo 363452350,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,3:00 PM,3:10 PM
202,Short,Short,Short,TeleGam: Combining Visualization and Verbalization for Interpretable Machine Learning,"Fred Hohman, Arjun Srinivasan, Steven Drucker",https://osf.io/p3wnm/,"While machine learning (ML) continues to find success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difficult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model’s predictions or comparisons between pairs of data instances. With the potential benefits of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Specifically, we present a prototype system, TeleGam, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TeleGam’s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TeleGam can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.",,,,,,vimeo 363042141,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,3:10 PM,3:20 PM
203,Short,Short,Short,Visualizing RNN States with Predictive Semantic Encodings,"Lindsey Sawatzky, Steven Bergner, Fred Popowich",https://arxiv.org/pdf/1908.00588.pdf,"Recurrent Neural Networks are an effective and prevalent tool used to model sequential data such as natural language text. However, their deep nature and massive number of parameters pose a challenge for those intending to study precisely how they work. We present a visual technique that gives a high level intuition behind the semantics of the hidden states within Recurrent Neural Networks. This semantic encoding allows for hidden states to be compared throughout the model independent of their internal details. The proposed technique is displayed in a proof of concept visualization tool which is demonstrated to visualize the natural language processing task of language modelling.",,,,,,vimeo 363951597,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,3:20 PM,3:30 PM
204,Short,Short,Short,FeatureExplorer: Interactive Feature Selection and Exploration of Regression Models for Hyperspectral Images,"Jieqiong Zhao, Morteza Karimzadeh, Ali Masjedi, Taojun Wang, Xiwen Zhang, Melba Crawford, David Ebert",https://arxiv.org/pdf/1908.00671.pdf,"Feature selection is used in machine learning to improve predictions, decrease computation time, reduce noise, and tune models based on limited sample data. In this article, we present FeatureExplorer, a visual analytics system that supports the dynamic evaluation of regression models and importance of feature subsets through the interactive selection of features in high-dimensional feature spaces typical of hyperspectral images. The interactive system allows users to iteratively refine and diagnose the model by selecting features based on their domain knowledge, interchangeable (correlated) features, feature importance, and the resulting model performance.",,,,,,vimeo 363456411,,,?,2019,Room 1,Wednesday,VIS Meets Machine Learning (Short),23-Oct,3:30 PM,3:40 PM
205,Short,Short,Short,A Markov Model of Users' Interactive Behavior in Scatterplots,"Emily Wall, Arup Arcalgud, Kuhu Gupta, Andrew Jo",,,,,,,,vimeo 363954377,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:00 AM,9:10 AM
206,Short,Short,Short,Slope-Dependent Rendering of Parallel Coordinates to Reduce Density Distortion and Ghost Clusters,"David Pomerenke, Frederik L. Dennig, Daniel Keim, Johannes Fuchs, Michael Blumenschein",https://arxiv.org/pdf/1908.00500.pdf,"Parallel coordinates are a popular technique to visualize multidimensional data. However, they face a significant problem influencing the perception and interpretation of patterns. The distance between two parallel lines differs based on their slope. Vertical lines are rendered longer and closer to each other than horizontal lines. This problem is inherent in the technique and has two main consequences: (1) clusters which have a steep slope between two axes are visually more prominent than horizontal clusters. (2) Noise and clutter can be perceived as clusters, as a few parallel vertical lines visually emerge as a ghost cluster. Our paper makes two contributions: First, we formalize the problem and show its impact. Second, we present a novel technique to reduce the effects by rendering the polylines of the parallel coordinates based on their slope: horizontal lines are rendered with the default width, lines with a steep slope with a thinner line. Our technique avoids density distortions of clusters, can be computed in linear time, and can be added on top of most parallel coordinate variations. To demonstrate the usefulness, we show examples and compare them to the classical rendering.",,,,,https://osf.io/sy3dv,vimeo 363951887,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:10 AM,9:20 AM
207,Short,Short,Short,Evaluating Ordering Strategies of Star Glyph Axes,"Matthias Miller, Xuan Zhang, Johannes Fuchs, Michael Blumenschein",https://arxiv.org/pdf/1908.00576.pdf,"Star glyphs are a well-researched visualization technique to represent multi-dimensional data. They are often used in small multiple settings for a visual comparison of many data points. However, their overall visual appearance is strongly influenced by the ordering of dimensions. To this end, two orthogonal categories of layout strategies are proposed in the literature: order dimensions by similarity to get homogeneously shaped glyphs vs. order by dissimilarity to emphasize spikes and salient shapes. While there is evidence that salient shapes support clustering tasks, evaluation, and direct comparison of data-driven ordering strategies has not received much research attention. We contribute an empirical user study to evaluate the efficiency, effectiveness, and user confidence in visual clustering tasks using star glyphs. In comparison to similarity-based ordering, our results indicate that dissimilarity-based star glyph layouts support users better in clustering tasks, especially when clutter is present.",,,https://osf.io/bje89/,https://osf.io/bje89/,https://osf.io/bje89/,vimeo 363452113,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:20 AM,9:30 AM
208,Short,Short,Short,Interactive Visualisation of Hierarchical Quantitative Data: an Evaluation,"Linda Woodburn, Yalong Yang, Kim Marriott",https://arxiv.org/pdf/1908.01277.pdf,"We have compared three common visualisations for hierarchical quantitative data, treemaps, icicle plots and sunburst charts as well as a semicircular variant of sunburst charts we call the sundown chart. In a pilot study, we found that the sunburst chart was least preferred. In a controlled study with 12 participants, we compared treemaps, icicle plots and sundown charts. Treemap was the least preferred and had a slower performance on a basic navigation task and slower performance and accuracy in hierarchy understanding tasks. The icicle plot and sundown chart had similar performance with slight user preference for the icicle plot.",,,,,https://github.com/ProcessFit/DataVis,vimeo 363040988,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:30 AM,9:40 AM
209,Short,Short,Short,Evidence for Area as the Primary Visual Cue in Pie Charts,Robert Kosara,https://osf.io/fcna4,"The long-standing assumption of angle as the primary visual cueused to read pie charts has recently been called into question. Weconducted a controlled, preregistered study using parallel-projected3D pie charts. Angle, area, and arc length differ dramatically whenprojected and change over a large range of values. Modeling thesechanges and comparing them to study participants’ estimates allowsus to rank the different visual cues by model fit. Area emerges asthe most likely cue used to read pie charts",,https://osf.io/3a5tq,https://osf.io/ra5tb/,https://osf.io/ra5tb/,https://osf.io/ra5tb/,vimeo 363041944,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:40 AM,9:50 AM
210,Short,Short,Short,Visual cues in estimation of part-to-whole comparison,Stephen Redmond,https://arxiv.org/ftp/arxiv/papers/1908/1908.00630.pdf,"Pie charts were first published in 1801 by William Playfair and have caused some controversy since. Despite the suggestions of many experts against their use, several empirical studies have shown that pie charts are at least as good as alternatives. From Brinton to Few on one side and Eells to Kosara on the other, there appears to have been a hundred-year war waged on the humble pie. In this paper a set of experiments are reported that compare the performance of pie charts and horizontal bar charts with various visual cues. Amazon’s Mechanical Turk service was employed to perform the tasks of estimating segments in various part-to-whole charts. The results lead to recommendations for data visualization professionals in developing dashboards.",,,,,,vimeo 363042298,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,9:50 AM,10:00 AM
211,Short,Short,Short,Towards a Design Space for Mitigating Cognitive Bias in Visual Analytics,"Emily Wall, John Stasko, Alex Endert",,,,,,,,vimeo 363451921,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,10:00 AM,10:10 AM
212,Short,Short,Short,Thumbnails for Data Stories: Survey of Current Practice,"Hwiyeon Kim, Juyoung Oh, Yunha Han, Sungahn Ko, Matthew Brehmer, Bum Chul Kwon",https://arxiv.org/abs/1908.06922,"When people browse online news, small thumbnail images accompanying links to articles attract their attention and help them to decide which articles to read. As an increasing proportion of online news can be construed as data journalism, we have witnessed a corresponding increase in the incorporation of visualization in article thumbnails. However, there is little research to support alternative design choices for visualization thumbnails, which include resizing, cropping, simplifying, and embellishing charts appearing within the body of the associated article. We therefore sought to better understand these design choices and determine what makes a visualization thumbnail inviting and interpretable. This paper presents our findings from a survey of visualization thumbnails collected online and from conversations with data journalists and news graphics designers. Our study reveals that there exists an uncharted design space, one that is in need of further empirical study. Our work can thus be seen as a first step toward providing structured guidance on how to design thumbnails for data stories",,,,,,,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,10:10 AM,10:20 AM
213,Short,Short,Short,Towards Quantifying multiple view layouts in visualisation as seen from research publications,"Hayder Mahdi Al-maneea, Jonathan C Roberts",,,,,,,,vimeo 363453583,,,?,2019,Room 1,Wednesday,"Perception, Cognition, and Visualization Design",23-Oct,10:20 AM,10:30 AM
214,Short,Short,Short,Data-Driven Colormap Optimization for 2D Scalar Field Visualization,"Qiong Zeng, Yinqiao Wang, Ivan Viola, Wenting Zhang, Jian Zhang, Changhe Tu, Yunhai Wang",,,,,,,,vimeo 363042086,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:00 AM,9:10 AM
215,Short,Short,Short,Evaluating Gradient Perception in Color-coded Scalar Fields,"Khairi Reda, Michael E. Papka",https://osf.io/2msfd,"Color mapping is a commonly used technique for visualizing scalar fields. While there exists advice for choosing effective colormaps, it is unclear if current guidelines apply equally across task types. We study the perception of gradients and evaluate the effectiveness of three colormaps at depicting gradient magnitudes. In a crowdsourced experiment, we determine the just-noticeable differences (JNDs) at which participants can reliably compare and judge variations in gradient between two scalar fields. We find that participants exhibited lower JNDs with a diverging (cool-warm) or a spectral (rainbow) scheme, as compared with a monotonic-luminance colormap (viridis). The results support a hypothesis that apparent discontinuities in the color ramp may help viewers discern subtle structural differences in gradient. We discuss these findings and highlight future research directions for colormap evaluation.",,https://osf.io/ng9qw,https://osf.io/ew638/,https://osf.io/ew638/,https://osf.io/ew638/,vimeo 363042264,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:10 AM,9:20 AM
216,Short,Short,Short,GalStamps: Analyzing Real and Simulated Galaxy Observations,"Nina McCurdy, Miriah Meyer",,,,,,,,vimeo 363040619,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:20 AM,9:30 AM
217,Short,Short,Short,Point Movement in a DSL for Higher-Order FEM Visualization,"Teodoro Collin, Charisee Chiw, L. Ridgway Scott, John Reppy, Gordon L Kindlmann",,,,,,,,vimeo 363040730,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:30 AM,9:40 AM
218,Short,Short,Short,Unsteady Flow Visualization via Physics based Pathline Exploration,"Duong Nguyen, Lei Zhang, Robert S. Laramee, David Thompson, Rodolfo Ostilla Monico, Guoning Chen",,,,,,,,vimeo 363042555,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:40 AM,9:50 AM
219,Short,Short,Short,Visualization of Symmetries in Fourth-Order Stiffness Tensors,"Chiara Hergl, Thomas Nagel, Olaf Kolditz, Gerik Scheuermann",,,,,,,,vimeo 363042029,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,9:50 AM,10:00 AM
220,Short,Short,Short,Hybrid Grids for Sparse Volume Rendering,"Stefan Zellmann, Deborah Meurer, Ulrich Lang",,,,,,,,vimeo 363954158,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,10:00 AM,10:10 AM
221,Short,Short,Short,Efficient Space Skipping and Adaptive Sampling of Unstructured Volumes using Hardware Accelerated Ray Tracing,"Nate Morrical, Will Usher, Ingo Wald, Valerio Pascucci",https://arxiv.org/pdf/1908.01906.pdf,"Sample based ray marching is an effective method for direct volume rendering of unstructured meshes. However, sampling such meshes remains expensive, and strategies to reduce the number of samples taken have received relatively little attention. In this paper, we introduce a method for rendering unstructured meshes using a combination of a coarse spatial acceleration structure and hardware-accelerated ray tracing. Our approach enables efficient empty space skipping and adaptive sampling of unstructured meshes, and outperforms a reference ray marcher by up to 7×.",,,,,,vimeo 363452086,,,?,2019,Room 1,Friday,"Scalar, vector, and tensor fields",25-Oct,10:10 AM,10:20 AM
222,Short,Short,Short,scenery - Flexible Virtual Reality Visualization on the Java VM,"Ulrik Günther, Tobias Pietzsch, Aryaman Gupta, Kyle Harrington, Stefan Gumhold, Pavel Tomancak, Ivo F. Sbalzarini",https://arxiv.org/pdf/1906.06726.pdf,"Life science today involves computational analysis of a large amount and variety of data, such as volumetric data acquired by state-of-the-art microscopes, or mesh data from analysis of such data or simulations. Visualization is often the first step in making sense of data, and a crucial part of building and debugging analysis pipelines. It is therefore important that visualizations can be quickly prototyped, as well as developed or embedded into full applications. In order to better judge spatiotemporal relationships, immersive hardware, such as Virtual or Augmented Reality (VR/AR) headsets and associated controllers are becoming invaluable tools. In this work we introduce scenery, a flexible VR/AR visualization framework for the Java VM that can handle mesh and large volumetric data, containing multiple views, timepoints, and color channels. scenery is free and open-source software, works on all major platforms, and uses the Vulkan or OpenGL rendering APIs. We introduce scenery’s main features and example applications, such as its use in VR for microscopy, in the biomedical image analysis software Fiji, or for visualising agent-based simulations.",,,,,,,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,2:20 PM,2:30 PM
223,Short,Short,Short,Interactive Dendritic Spine Analysis Based on 3D Morphological Features,"JunYoung Choi, Sang-Eun Lee, Eunji Cho, Yutaro Kashiwagi, Shigeo Okabe, Sunghoe Chang, Won-Ki Jeong",,,,,,,,vimeo 364567245,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,2:30 PM,2:40 PM
224,Short,Short,Short,High Fidelity Visualization of Large Scale Digitally Reconstructed Brain Circuitry with Signed Distance Functions,"Jonas Karlsson, Marwan Abdellah, Sebastien Speierer, Alessandro Enrico Foni, Samuel Lapere, Felix Schurmann",,,,,,,,vimeo 363452920,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,2:40 PM,2:50 PM
225,Short,Short,Short,Visual Inspection of DBS Efficacy,"Brad Eric Hollister, Chris Butson, Gordon Duffley, Chris R. Johnson, Paul Rosen",,,,,,,,vimeo 364569960,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,2:50 PM,3:00 PM
226,Short,Short,Short,TempoCave: Visualizing Dynamic Connectome Datasets to Support Cognitive Behavioral Therapy,"Ran Xu, Manu Mathew Thomas, Alex Leow, Olusola A. Ajilore, Angus G. Forbes",https://arxiv.org/pdf/1906.07837.pdf,"We introduce TempoCave, a novel visualization application for analyzing dynamic brain networks, or connectomes. TempoCave provides a range of functionality to explore metrics related to the activity patterns and modular affiliations of different regions in the brain. These patterns are calculated by processing raw data retrieved functional magnetic resonance imaging (fMRI) scans, which creates a network of weighted edges between each brain region, where the weight indicates how likely these regions are to activate synchronously. In particular, we support the analysis needs of clinical psychologists, who examine these modular affiliations and weighted edges and their temporal dynamics, utilizing them to understand relationships between neurological disorders and brain activity, which could have significant impact on the way in which patients are diagnosed and treated. We summarize the core functionality of TempoCave, which supports a range of comparative tasks, and runs both in a desktop mode and in an immersive mode. Furthermore, we present a real world use case that analyzes pre- and post-treatment connectome datasets from 27 subjects in a clinical study investigating the use of cognitive behavior therapy to treat major depression disorder, indicating that TempoCave can provide new insight into the dynamic behavior of the human brain.",,,,,https://github.com/CreativeCodingLab/TempoCave,vimeo 363456447,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,3:00 PM,3:10 PM
227,Short,Short,Short,RuleVis: Constructing Patterns and Rules for Rule-based Models,"David Abramov, Jasmine Tan Otto, Mahika Dubey, Cassia Artanegara, Pierre Boutillier, Walter Fontana, Angus G. Forbes",,,,,,,,vimeo 363456476,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,3:10 PM,3:20 PM
228,Short,Short,Short,ElectroLens: Understanding atomistic simulations through spatially-resolved visualization of high-dimensional features,"Xiangyun Lei, Fred Hohman, Duen Horng Chau, Andrew J Medford",https://arxiv.org/pdf/1908.08381.pdf,"In recent years, machine learning (ML) has gained significant popularity in the field of chemical informatics and electronic structure theory. These techniques often require researchers to engineer abstract “features” that encode chemical concepts into a mathematical form compatible with the input to machine-learning models. However, there is no existing tool to connect these abstract features back to the actual chemical system, making it difficult to diagnose failures and to build intuition about the meaning of the features. We present ElectroLens, a new visualization tool for high-dimensional spatially-resolved features to tackle this problem. The tool visualizes high-dimensional data sets for atomistic and electron environment features by a series of linked 3D views and 2D plots. The tool is able to connect different derived features and their corresponding regions in 3D via interactive selection. It is built to be scalable, and integrate with existing infrastructure.",,,,,,vimeo 363453632,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,3:20 PM,3:30 PM
229,Short,Short,Short,Analyzing Time Attributes in Event Sequences,"Jessica Magallanes, Lindsey van Gemeren, Steven Wood, Maria-Cruz Villa-Uriol",https://arxiv.org/pdf/1908.00903.pdf,"Event data is present in a variety of domains such as electronic health records, daily living activities and web clickstream records. Current visualization methods to explore event data focus on discovering sequential patterns but present limitations when studying time attributes in event sequences. Time attributes are especially important when studying waiting times or lengths of visit in patient flow analysis. We propose a visual analytics methodology that allows the identification of trends and outliers in respect of duration and time of occurrence in event sequences. The proposed method presents event data using a single Sequential and Time Patterns overview. User-driven alignment by multiple events, sorting by sequence similarity and a novel visual encoding of events allows the comparison of time trends across and within sequences. The proposed visualization allows the derivation of findings that otherwise could not be obtained using traditional visualizations. The proposed methodology has been applied to a real-world dataset provided by Sheffield Teaching Hospitals NHS Foundation Trust, for which four classes of conclusions were derived.",,,,,,,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,3:30 PM,3:40 PM
230,Short,Short,Short,Evaluating Alignment Approaches in Superimposed Time-series and Temporal Event-sequence Visualizations,"Yixuan Zhang, Sara Di Bartolomeo, Fangfang Sheng, Holly Jimison, Cody Dunne",https://arxiv.org/pdf/1908.07316.pdf,"Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using singleevent alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dualevent alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness—71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness—88% vs. 36% for DualStretch— completion time—55 seconds vs. 101 seconds for DualLeft—and error—1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5",,,https://osf.io/78fs5/,https://osf.io/78fs5/,https://osf.io/78fs5/,vimeo 363452044,,,?,2019,Room 1,Thursday,"Biology, Chemistry, and Medicine",24-Oct,3:40 PM,3:50 PM
231,Short,Short,Short,Designing Visual Guides for Casual Listeners of Live Orchestral Music,"Catherine Solis, Fahimeh Rajabiyazdi, Fanny Chevalier",,,,,,,,vimeo 364567296,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,4:10 PM,4:20 PM
232,Short,Short,Short,Uncovering Data Landscapes through Data Reconnaissance and Task Wrangling,"Anamaria Crisan, Tamara Munzner",,,,,,,,vimeo 363042588,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,4:20 PM,4:30 PM
233,Short,Short,Short,Sabrina: Modeling and Visualization of Economy Data with Incremental Domain Knowledge,"Alessio Arleo, Johannes Sorger, Chao Jia, Christos Tsigkanos, Roger A. Leite, Ilir Murturi, Manfred Klaffenboeck, Silvia Miksch, Shahram Dustdar, Michael Wimmer",https://arxiv.org/pdf/1908.07479.pdf,"Investment planning requires knowledge of the financial landscape on a large scale, both in terms of geo-spatial and industry sector distribution. There is plenty of data available, but it is scattered across heterogeneous sources (newspapers, open data, etc.), which makes it difficult for financial analysts to understand the big picture. In this paper, we present Sabrina, a financial data analysis and visualization approach that incorporates a pipeline for the generation of firm-to-firm financial transaction networks. The pipeline is capable of fusing the ground truth on individual firms in a region with (incremental) domain knowledge on general macroscopic aspects of the economy. Sabrina unites these heterogeneous data sources within a uniform visual interface that enables the visual analysis process. In a user study with three domain experts, we illustrate the usefulness of Sabrina, which eases their analysis process.",,,,,,vimeo 363040561,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,4:30 PM,4:40 PM
234,Short,Short,Short,Visual Analysis of the Time Management of Learning Multiple Courses in Online Learning Environment,"Huan He, Bo Dong, Qinghua Zheng, Dehai Di, Yating Lin",,,,,,,,vimeo 363452286,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,4:40 PM,4:50 PM
235,Short,Short,Short,H-Matrix: Hierarchical Matrix for Visual Analysis of Cross-Linguistic Features in Large Learner Corpora,"Mariana Shimabukuro, Jessica Zipf, Mennatallah El-Assady, Christopher Collins",,,,,,,,vimeo 363042512,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,4:50 PM,5:00 PM
236,Short,Short,Short,OCTVis: Ontology-based Comparison of Topic Models,"Amon Ge, Hyeju Jang, Giuseppe Carenini, Kendall Ho, Young Ji Lee",,,,,,,,vimeo 363452963,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,5:00 PM,5:10 PM
237,Short,Short,Short,MissBi: Visual Analysis of Missing Links in Bipartite Networks,"Jian Zhao, Maoyuan Sun, Francine Chen, Patrick Chiu",,,,,,,,,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,5:10 PM,5:20 PM
238,Short,Short,Short,FacIt: Factorizing Tensors into Interpretable and Scrutinizable Patterns,"Xidao Wen, Yu-Ru Lin, Yongsu Ahn, Konstantinos Pelechrinis, Xi Liu, Nan Cao",,,,,,,,vimeo 363453555,,,?,2019,Room 1,Tuesday,Systems and Design Studies,22-Oct,5:20 PM,5:30 PM
239,Short,Short,Short,Interpreting Distortions in Dimensionality Reduction by Superimposing Neighbourhood Graphs,"Benoît Colange, Laurent Vuillon, Sylvain Lespinats, Denys Dutykh",https://arxiv.org/abs/1909.12902,"To perform visual data exploration, many dimensionality reduction methods have been developed. These tools allow data analysts to represent multidimensional data in a 2D or 3D space, while preserving as much relevant information as possible. Yet, they cannot preserve all structures simultaneously and they induce some unavoidable distortions. Hence, many criteria have been introduced to evaluate a map’s overall quality, mostly based on the preservation of neighbourhoods. Such global indicators are currently used to compare several maps, which helps to choose the most appropriate mapping method and its hyperparameters. However, those aggregated indicators tend to hide the local repartition of distortions. Thereby, they need to be supplemented by local evaluation to ensure correct interpretation of maps. In this paper, we describe a new method, called MING, for “Map Interpretation using Neighbourhood Graphs”. It offers a graphical interpretation of pairs of map quality indicators, as well as local evaluation of the distortions. This is done by displaying on the map the nearest neighbours graphs computed in the data space and in the embedding. Shared and unshared edges exhibit reliable and unreliable neighbourhood information conveyed by the mapping. By this mean, analysts may determine whether proximity (or remoteness) of points on the map faithfully represents similarity (or dissimilarity) of original data, within the meaning of a chosen map quality criteria. We apply this approach to two pairs of widespread indicators: precision/recall and trustworthiness/continuity, chosen for their wide use in the community, which will allow an easy handling by users.",,,,,,vimeo 363451896,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,4:10 PM,4:20 PM
240,Short,Short,Short,Hi-D Maps: An Interactive Visualization Technique for Multi-dimensional Categorical Data.,"Radi Muhammad Reza, Benjamin Watson",https://osf.io/ufzgd/,"In this paper, we presentHi-D maps, a novel method for the visual-ization of multi-dimensional categorical data. Our work addressesthe scarcity of techniques for visualizing a large number of data-dimensions in an effective and space-efficient manner. We havemapped the full data-space onto a 2D regular polygonal region. Thepolygon is cut hierarchically with lines parallel to a user-controlled,ordered sequence of sides, each representing a dimension. We haveused multiple visual cues such as orientation, thickness, color, count-able glyphs, and text to depict cross-dimensional information. Wehave added interactivity and hierarchical browsing to facilitate flex-ible exploration of the display: small areas can be scrutinized fordetails. Thus, our method is also easily extendable to visualize hierarchical information. Our glyph animations add an engagingaesthetic during interaction. Like many visualizations, Hi-D mapsbecome less effective when a large number of dimensions stressesperceptual limits, but Hi-D maps may add clarity before those limitsare reached.",,,,,,,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,4:20 PM,4:30 PM
241,Short,Short,Short,Conditional Parallel Coordinates,Daniel Weidele,https://arxiv.org/pdf/1906.07716.pdf,"Parallel Coordinates [11, 12] are a popular data visualization technique for multivariate data. Dating back to as early as 1880 [8] PC are nearly as old as John Snow’s famous cholera outbreak map [18] of 1855, which is frequently regarded as a historic landmark for modern data visualization. Numerous extensions have been proposed to address integrity, scalability and readability. We make a new case to employ PC on conditional data, where additional dimensions are only unfolded if certain criteria are met in an observation. Compared to standard PC which operate on a flat set of dimensions the ontology of our input to Conditional Parallel Coordinates is of hierarchical nature. We therefore briefly review related work around hierarchical PC using aggregation or nesting techniques. Our contribution is a visualization to seamlessly adapt PC for conditional data under preservation of intuitive interaction patterns to select or highlight polylines. We conclude with intuitions on how to operate CPC on two data sets: an AutoML hyperparameter search log, and session results from a conversational agent.",,,,,,vimeo 363040925,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,4:30 PM,4:40 PM
242,Short,Short,Short,Towards Enhancing RadViz Analysis and Interpretation,"Marco Angelini, Graziano Blasilli, Simone Lenti, Alessia Palleschi, Giuseppe Santucci",,,,,,,,vimeo 363453287,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,4:40 PM,4:50 PM
243,Short,Short,Short,Time Varying Predominance Tag Maps,"Martin Reckziegel, Stefan Jänicke",,,,,,,,vimeo 363041739,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,4:50 PM,5:00 PM
244,Short,Short,Short,SAX Navigator: Time Series Exploration Through Hierarchical Clustering,"Nicholas Ruta, Naoko Sawada, Katy McKeough, Michael Behrisch, Johanna Beyer",https://arxiv.org/pdf/1908.05505.pdf,"Comparing many long time series is challenging to do by hand. Clustering time series enables data analysts to discover relevance between and anomalies among multiple time series. However, even after reasonable clustering, analysts have to scrutinize correlations between clusters or similarities within a cluster. We developed SAX Navigator, an interactive visualization tool, that allows users to hierarchically explore global patterns as well as individual observations across large collections of time series data. Our visualization provides a unique way to navigate time series that involves a “vocabulary of patterns” developed by using a dimensionality reduction technique, Symbolic Aggregate approXimation (SAX). With SAX, the time series data clusters efficiently and is quicker to query at scale. We demonstrate the ability of SAX Navigator to analyze patterns in large time series data based on three case studies for an astronomy data set. We verify the usability of our system through a think-aloud study with an astronomy domain scientist.",,,,,,vimeo 364567202,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,5:00 PM,5:10 PM
245,Short,Short,Short,Nonuniform Timeslicing of Dynamic Graphs Based on Visual Complexity,"Yong Wang, Daniel Archambault, Hammad Haleem, Torsten Moeller, Yanhong Wu, Huamin Qu",https://arxiv.org/pdf/1907.12015.pdf,"Uniform timeslicing of dynamic graphs has been used due to its convenience and uniformity across the time dimension. However, uniform timeslicing does not take the data set into account, which can generate cluttered timeslices with edge bursts and empty timeslices with few interactions. The graph mining filed has explored nonuniform timeslicing methods specifically designed to preserve graph features for mining tasks. In this paper, we propose a nonuniform timeslicing approach for dynamic graph visualization. Our goal is to create timeslices of equal visual complexity. To this end, we adapt histogram equalization to create timeslices with a similar number of events, balancing the visual complexity across timeslices and conveying more important details of timeslices with bursting edges. A case study has been conducted, in comparison with uniform timeslicing, to demonstrate the effectiveness of our approach.",,,,,,vimeo 363040656,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,5:10 PM,5:20 PM
246,Short,Short,Short,Interactive Bicluster Aggregation in Bipartite Graphs,"Maoyuan Sun, David Koop, Jian Zhao, Chris North, Naren Ramakrishnan",,,,,,,,vimeo 363040807,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,5:20 PM,5:30 PM
247,Short,Short,Short,Overlap-Free Drawing of Generalized Pythagoras Trees for Hierarchy Visualization,"Tanja Munz, Michael Burch, Toon van Benthem, Yoeri Poels, Fabian Beck, Daniel Weiskopf",https://arxiv.org/pdf/1907.12845.pdf,"Generalized Pythagoras trees were developed for visualizing hierarchical data, producing organic, fractal-like representations. However, the drawback of the original layout algorithm is visual overlap of tree branches. To avoid such overlap, we introduce an adapted drawing algorithm using ellipses instead of circles to recursively place tree nodes representing the subhierarchies. Our technique is demonstrated by resolving overlap in diverse real-world and generated datasets, while comparing the results to the original approach.",,,,,,vimeo 363452307,,,?,2019,Room 1,Thursday,"Multi-Dimensional Data, Time Series, Graphs, and Trees",24-Oct,5:30 PM,5:40 PM